{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use LangChain, GPT and Deep Lake to work with code base\n",
    "In this tutorial, we are going to use Langchain + Deep Lake with GPT to analyze the code base of the LangChain itself. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare data:\n",
    "   1. Upload all python project files using the `langchain.document_loaders.TextLoader`. We will call these files the **documents**.\n",
    "   2. Split all documents to chunks using the `langchain.text_splitter.CharacterTextSplitter`.\n",
    "   3. Embed chunks and upload them into the DeepLake using `langchain.embeddings.openai.OpenAIEmbeddings` and `langchain.vectorstores.DeepLake`\n",
    "2. Question-Answering:\n",
    "   1. Build a chain from `langchain.chat_models.ChatOpenAI` and `langchain.chains.ConversationalRetrievalChain`\n",
    "   2. Prepare questions.\n",
    "   3. Get answers running the chain.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Integration preparations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set up keys for external services and install necessary python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python3 -m pip install --upgrade langchain deeplake openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up OpenAI embeddings, Deep Lake multi-modal vector store api and authenticate. \n",
    "\n",
    "For full documentation of Deep Lake please follow https://docs.activeloop.ai/ and API reference https://docs.deeplake.ai/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] # = getpass()\n",
    "# Please manually enter OpenAI Key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate into Deep Lake if you want to create your own dataset and publish it. You can get an API key from the platform at [app.activeloop.ai](https://app.activeloop.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# os.environ['ACTIVELOOP_TOKEN'] = getpass.getpass('Activeloop Token:')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all repository files. Here we assume this notebook is downloaded as the part of the langchain fork and we work with the python files of the `langchain` repo.\n",
    "\n",
    "If you want to use files from different repo, change `root_dir` to the root dir of your repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# root_dir = '../../../..'\n",
    "root_dir = '../data'\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith('.py') and 'venv/' not in dirpath:\n",
    "            try: \n",
    "                loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "                docs.extend(loader.load_and_split())\n",
    "            except Exception as e: \n",
    "                pass\n",
    "print(f'{len(docs)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, chunk the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1109, which is longer than the specified 1000\n",
      "Created a chunk of size 1194, which is longer than the specified 1000\n",
      "Created a chunk of size 3122, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 3569, which is longer than the specified 1000\n",
      "Created a chunk of size 1121, which is longer than the specified 1000\n",
      "Created a chunk of size 1155, which is longer than the specified 1000\n",
      "Created a chunk of size 1062, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 2432, which is longer than the specified 1000\n",
      "Created a chunk of size 2357, which is longer than the specified 1000\n",
      "Created a chunk of size 3133, which is longer than the specified 1000\n",
      "Created a chunk of size 2082, which is longer than the specified 1000\n",
      "Created a chunk of size 1003, which is longer than the specified 1000\n",
      "Created a chunk of size 1876, which is longer than the specified 1000\n",
      "Created a chunk of size 1438, which is longer than the specified 1000\n",
      "Created a chunk of size 3790, which is longer than the specified 1000\n",
      "Created a chunk of size 1165, which is longer than the specified 1000\n",
      "Created a chunk of size 1396, which is longer than the specified 1000\n",
      "Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1402, which is longer than the specified 1000\n",
      "Created a chunk of size 1292, which is longer than the specified 1000\n",
      "Created a chunk of size 1573, which is longer than the specified 1000\n",
      "Created a chunk of size 3048, which is longer than the specified 1000\n",
      "Created a chunk of size 1059, which is longer than the specified 1000\n",
      "Created a chunk of size 1115, which is longer than the specified 1000\n",
      "Created a chunk of size 1035, which is longer than the specified 1000\n",
      "Created a chunk of size 1882, which is longer than the specified 1000\n",
      "Created a chunk of size 1431, which is longer than the specified 1000\n",
      "Created a chunk of size 1108, which is longer than the specified 1000\n",
      "Created a chunk of size 1279, which is longer than the specified 1000\n",
      "Created a chunk of size 1164, which is longer than the specified 1000\n",
      "Created a chunk of size 1195, which is longer than the specified 1000\n",
      "Created a chunk of size 1311, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n",
      "Created a chunk of size 1103, which is longer than the specified 1000\n",
      "Created a chunk of size 2226, which is longer than the specified 1000\n",
      "Created a chunk of size 2220, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1650, which is longer than the specified 1000\n",
      "Created a chunk of size 1211, which is longer than the specified 1000\n",
      "Created a chunk of size 1114, which is longer than the specified 1000\n",
      "Created a chunk of size 1061, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1683, which is longer than the specified 1000\n",
      "Created a chunk of size 1064, which is longer than the specified 1000\n",
      "Created a chunk of size 1022, which is longer than the specified 1000\n",
      "Created a chunk of size 2032, which is longer than the specified 1000\n",
      "Created a chunk of size 1073, which is longer than the specified 1000\n",
      "Created a chunk of size 1307, which is longer than the specified 1000\n",
      "Created a chunk of size 1851, which is longer than the specified 1000\n",
      "Created a chunk of size 1259, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1146, which is longer than the specified 1000\n",
      "Created a chunk of size 1140, which is longer than the specified 1000\n",
      "Created a chunk of size 1146, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1198, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n",
      "Created a chunk of size 1430, which is longer than the specified 1000\n",
      "Created a chunk of size 1607, which is longer than the specified 1000\n",
      "Created a chunk of size 1648, which is longer than the specified 1000\n",
      "Created a chunk of size 1302, which is longer than the specified 1000\n",
      "Created a chunk of size 1245, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 1373, which is longer than the specified 1000\n",
      "Created a chunk of size 1011, which is longer than the specified 1000\n",
      "Created a chunk of size 1083, which is longer than the specified 1000\n",
      "Created a chunk of size 1181, which is longer than the specified 1000\n",
      "Created a chunk of size 2864, which is longer than the specified 1000\n",
      "Created a chunk of size 1417, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1034, which is longer than the specified 1000\n",
      "Created a chunk of size 1117, which is longer than the specified 1000\n",
      "Created a chunk of size 2264, which is longer than the specified 1000\n",
      "Created a chunk of size 1424, which is longer than the specified 1000\n",
      "Created a chunk of size 1205, which is longer than the specified 1000\n",
      "Created a chunk of size 1467, which is longer than the specified 1000\n",
      "Created a chunk of size 1696, which is longer than the specified 1000\n",
      "Created a chunk of size 1651, which is longer than the specified 1000\n",
      "Created a chunk of size 1108, which is longer than the specified 1000\n",
      "Created a chunk of size 1804, which is longer than the specified 1000\n",
      "Created a chunk of size 2165, which is longer than the specified 1000\n",
      "Created a chunk of size 2174, which is longer than the specified 1000\n",
      "Created a chunk of size 2301, which is longer than the specified 1000\n",
      "Created a chunk of size 3017, which is longer than the specified 1000\n",
      "Created a chunk of size 2971, which is longer than the specified 1000\n",
      "Created a chunk of size 1233, which is longer than the specified 1000\n",
      "Created a chunk of size 3260, which is longer than the specified 1000\n",
      "Created a chunk of size 1185, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 3480, which is longer than the specified 1000\n",
      "Created a chunk of size 1329, which is longer than the specified 1000\n",
      "Created a chunk of size 2443, which is longer than the specified 1000\n",
      "Created a chunk of size 1472, which is longer than the specified 1000\n",
      "Created a chunk of size 2459, which is longer than the specified 1000\n",
      "Created a chunk of size 1397, which is longer than the specified 1000\n",
      "Created a chunk of size 1986, which is longer than the specified 1000\n",
      "Created a chunk of size 2475, which is longer than the specified 1000\n",
      "Created a chunk of size 1518, which is longer than the specified 1000\n",
      "Created a chunk of size 1068, which is longer than the specified 1000\n",
      "Created a chunk of size 2807, which is longer than the specified 1000\n",
      "Created a chunk of size 2223, which is longer than the specified 1000\n",
      "Created a chunk of size 2075, which is longer than the specified 1000\n",
      "Created a chunk of size 1517, which is longer than the specified 1000\n",
      "Created a chunk of size 1541, which is longer than the specified 1000\n",
      "Created a chunk of size 1518, which is longer than the specified 1000\n",
      "Created a chunk of size 1940, which is longer than the specified 1000\n",
      "Created a chunk of size 2347, which is longer than the specified 1000\n",
      "Created a chunk of size 1914, which is longer than the specified 1000\n",
      "Created a chunk of size 1522, which is longer than the specified 1000\n",
      "Created a chunk of size 1728, which is longer than the specified 1000\n",
      "Created a chunk of size 1644, which is longer than the specified 1000\n",
      "Created a chunk of size 1127, which is longer than the specified 1000\n",
      "Created a chunk of size 1976, which is longer than the specified 1000\n",
      "Created a chunk of size 1361, which is longer than the specified 1000\n",
      "Created a chunk of size 1156, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1517, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 3201, which is longer than the specified 1000\n",
      "Created a chunk of size 1034, which is longer than the specified 1000\n",
      "Created a chunk of size 1702, which is longer than the specified 1000\n",
      "Created a chunk of size 1926, which is longer than the specified 1000\n",
      "Created a chunk of size 2729, which is longer than the specified 1000\n",
      "Created a chunk of size 1609, which is longer than the specified 1000\n",
      "Created a chunk of size 1310, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 2429, which is longer than the specified 1000\n",
      "Created a chunk of size 1457, which is longer than the specified 1000\n",
      "Created a chunk of size 1994, which is longer than the specified 1000\n",
      "Created a chunk of size 1177, which is longer than the specified 1000\n",
      "Created a chunk of size 1647, which is longer than the specified 1000\n",
      "Created a chunk of size 1113, which is longer than the specified 1000\n",
      "Created a chunk of size 3264, which is longer than the specified 1000\n",
      "Created a chunk of size 1073, which is longer than the specified 1000\n",
      "Created a chunk of size 1364, which is longer than the specified 1000\n",
      "Created a chunk of size 2191, which is longer than the specified 1000\n",
      "Created a chunk of size 2196, which is longer than the specified 1000\n",
      "Created a chunk of size 1276, which is longer than the specified 1000\n",
      "Created a chunk of size 1947, which is longer than the specified 1000\n",
      "Created a chunk of size 1061, which is longer than the specified 1000\n",
      "Created a chunk of size 1525, which is longer than the specified 1000\n",
      "Created a chunk of size 1231, which is longer than the specified 1000\n",
      "Created a chunk of size 2923, which is longer than the specified 1000\n",
      "Created a chunk of size 1355, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1027, which is longer than the specified 1000\n",
      "Created a chunk of size 2427, which is longer than the specified 1000\n",
      "Created a chunk of size 1205, which is longer than the specified 1000\n",
      "Created a chunk of size 1274, which is longer than the specified 1000\n",
      "Created a chunk of size 2182, which is longer than the specified 1000\n",
      "Created a chunk of size 1157, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 2226, which is longer than the specified 1000\n",
      "Created a chunk of size 1558, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 2001, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1034, which is longer than the specified 1000\n",
      "Created a chunk of size 1229, which is longer than the specified 1000\n",
      "Created a chunk of size 2487, which is longer than the specified 1000\n",
      "Created a chunk of size 1025, which is longer than the specified 1000\n",
      "Created a chunk of size 1291, which is longer than the specified 1000\n",
      "Created a chunk of size 1240, which is longer than the specified 1000\n",
      "Created a chunk of size 1035, which is longer than the specified 1000\n",
      "Created a chunk of size 1521, which is longer than the specified 1000\n",
      "Created a chunk of size 2345, which is longer than the specified 1000\n",
      "Created a chunk of size 1256, which is longer than the specified 1000\n",
      "Created a chunk of size 1291, which is longer than the specified 1000\n",
      "Created a chunk of size 1253, which is longer than the specified 1000\n",
      "Created a chunk of size 1084, which is longer than the specified 1000\n",
      "Created a chunk of size 2351, which is longer than the specified 1000\n",
      "Created a chunk of size 1086, which is longer than the specified 1000\n",
      "Created a chunk of size 1258, which is longer than the specified 1000\n",
      "Created a chunk of size 1318, which is longer than the specified 1000\n",
      "Created a chunk of size 1118, which is longer than the specified 1000\n",
      "Created a chunk of size 1712, which is longer than the specified 1000\n",
      "Created a chunk of size 1095, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 1211, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 1337, which is longer than the specified 1000\n",
      "Created a chunk of size 1594, which is longer than the specified 1000\n",
      "Created a chunk of size 1512, which is longer than the specified 1000\n",
      "Created a chunk of size 1935, which is longer than the specified 1000\n",
      "Created a chunk of size 1020, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n",
      "Created a chunk of size 2264, which is longer than the specified 1000\n",
      "Created a chunk of size 2733, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n",
      "Created a chunk of size 1391, which is longer than the specified 1000\n",
      "Created a chunk of size 3136, which is longer than the specified 1000\n",
      "Created a chunk of size 1223, which is longer than the specified 1000\n",
      "Created a chunk of size 1277, which is longer than the specified 1000\n",
      "Created a chunk of size 1429, which is longer than the specified 1000\n",
      "Created a chunk of size 1166, which is longer than the specified 1000\n",
      "Created a chunk of size 1379, which is longer than the specified 1000\n",
      "Created a chunk of size 2433, which is longer than the specified 1000\n",
      "Created a chunk of size 1386, which is longer than the specified 1000\n",
      "Created a chunk of size 1368, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1008, which is longer than the specified 1000\n",
      "Created a chunk of size 1010, which is longer than the specified 1000\n",
      "Created a chunk of size 1028, which is longer than the specified 1000\n",
      "Created a chunk of size 2321, which is longer than the specified 1000\n",
      "Created a chunk of size 2826, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 2101, which is longer than the specified 1000\n",
      "Created a chunk of size 1232, which is longer than the specified 1000\n",
      "Created a chunk of size 1392, which is longer than the specified 1000\n",
      "Created a chunk of size 2300, which is longer than the specified 1000\n",
      "Created a chunk of size 1592, which is longer than the specified 1000\n",
      "Created a chunk of size 1375, which is longer than the specified 1000\n",
      "Created a chunk of size 3466, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1074, which is longer than the specified 1000\n",
      "Created a chunk of size 1083, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1485, which is longer than the specified 1000\n",
      "Created a chunk of size 1213, which is longer than the specified 1000\n",
      "Created a chunk of size 1782, which is longer than the specified 1000\n",
      "Created a chunk of size 1118, which is longer than the specified 1000\n",
      "Created a chunk of size 1620, which is longer than the specified 1000\n",
      "Created a chunk of size 1950, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1501, which is longer than the specified 1000\n",
      "Created a chunk of size 1208, which is longer than the specified 1000\n",
      "Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1219, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1364, which is longer than the specified 1000\n",
      "Created a chunk of size 1212, which is longer than the specified 1000\n",
      "Created a chunk of size 1414, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1283, which is longer than the specified 1000\n",
      "Created a chunk of size 1029, which is longer than the specified 1000\n",
      "Created a chunk of size 1269, which is longer than the specified 1000\n",
      "Created a chunk of size 3173, which is longer than the specified 1000\n",
      "Created a chunk of size 1168, which is longer than the specified 1000\n",
      "Created a chunk of size 1352, which is longer than the specified 1000\n",
      "Created a chunk of size 1941, which is longer than the specified 1000\n",
      "Created a chunk of size 1260, which is longer than the specified 1000\n",
      "Created a chunk of size 1195, which is longer than the specified 1000\n",
      "Created a chunk of size 2147, which is longer than the specified 1000\n",
      "Created a chunk of size 1183, which is longer than the specified 1000\n",
      "Created a chunk of size 1253, which is longer than the specified 1000\n",
      "Created a chunk of size 1411, which is longer than the specified 1000\n",
      "Created a chunk of size 1160, which is longer than the specified 1000\n",
      "Created a chunk of size 1058, which is longer than the specified 1000\n",
      "Created a chunk of size 1230, which is longer than the specified 1000\n",
      "Created a chunk of size 1848, which is longer than the specified 1000\n",
      "Created a chunk of size 1418, which is longer than the specified 1000\n",
      "Created a chunk of size 1069, which is longer than the specified 1000\n",
      "Created a chunk of size 1061, which is longer than the specified 1000\n",
      "Created a chunk of size 2573, which is longer than the specified 1000\n",
      "Created a chunk of size 1224, which is longer than the specified 1000\n",
      "Created a chunk of size 1999, which is longer than the specified 1000\n",
      "Created a chunk of size 1029, which is longer than the specified 1000\n",
      "Created a chunk of size 1031, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1030, which is longer than the specified 1000\n",
      "Created a chunk of size 1026, which is longer than the specified 1000\n",
      "Created a chunk of size 1019, which is longer than the specified 1000\n",
      "Created a chunk of size 1512, which is longer than the specified 1000\n",
      "Created a chunk of size 1262, which is longer than the specified 1000\n",
      "Created a chunk of size 1077, which is longer than the specified 1000\n",
      "Created a chunk of size 2482, which is longer than the specified 1000\n",
      "Created a chunk of size 1416, which is longer than the specified 1000\n",
      "Created a chunk of size 1120, which is longer than the specified 1000\n",
      "Created a chunk of size 1033, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 2538, which is longer than the specified 1000\n",
      "Created a chunk of size 1336, which is longer than the specified 1000\n",
      "Created a chunk of size 2622, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 1056, which is longer than the specified 1000\n",
      "Created a chunk of size 1195, which is longer than the specified 1000\n",
      "Created a chunk of size 1040, which is longer than the specified 1000\n",
      "Created a chunk of size 1497, which is longer than the specified 1000\n",
      "Created a chunk of size 1626, which is longer than the specified 1000\n",
      "Created a chunk of size 1148, which is longer than the specified 1000\n",
      "Created a chunk of size 1410, which is longer than the specified 1000\n",
      "Created a chunk of size 1152, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n",
      "Created a chunk of size 1221, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1506, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1338, which is longer than the specified 1000\n",
      "Created a chunk of size 1154, which is longer than the specified 1000\n",
      "Created a chunk of size 1249, which is longer than the specified 1000\n",
      "Created a chunk of size 2432, which is longer than the specified 1000\n",
      "Created a chunk of size 1017, which is longer than the specified 1000\n",
      "Created a chunk of size 1304, which is longer than the specified 1000\n",
      "Created a chunk of size 1224, which is longer than the specified 1000\n",
      "Created a chunk of size 1362, which is longer than the specified 1000\n",
      "Created a chunk of size 1379, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 1310, which is longer than the specified 1000\n",
      "Created a chunk of size 1133, which is longer than the specified 1000\n",
      "Created a chunk of size 1279, which is longer than the specified 1000\n",
      "Created a chunk of size 1176, which is longer than the specified 1000\n",
      "Created a chunk of size 1982, which is longer than the specified 1000\n",
      "Created a chunk of size 1542, which is longer than the specified 1000\n",
      "Created a chunk of size 1134, which is longer than the specified 1000\n",
      "Created a chunk of size 1011, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 2082, which is longer than the specified 1000\n",
      "Created a chunk of size 1061, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 1979, which is longer than the specified 1000\n",
      "Created a chunk of size 1681, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 1237, which is longer than the specified 1000\n",
      "Created a chunk of size 1339, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1245, which is longer than the specified 1000\n",
      "Created a chunk of size 2817, which is longer than the specified 1000\n",
      "Created a chunk of size 1104, which is longer than the specified 1000\n",
      "Created a chunk of size 1449, which is longer than the specified 1000\n",
      "Created a chunk of size 2248, which is longer than the specified 1000\n",
      "Created a chunk of size 1589, which is longer than the specified 1000\n",
      "Created a chunk of size 1501, which is longer than the specified 1000\n",
      "Created a chunk of size 1068, which is longer than the specified 1000\n",
      "Created a chunk of size 1318, which is longer than the specified 1000\n",
      "Created a chunk of size 1532, which is longer than the specified 1000\n",
      "Created a chunk of size 1535, which is longer than the specified 1000\n",
      "Created a chunk of size 1197, which is longer than the specified 1000\n",
      "Created a chunk of size 1303, which is longer than the specified 1000\n",
      "Created a chunk of size 1367, which is longer than the specified 1000\n",
      "Created a chunk of size 1623, which is longer than the specified 1000\n",
      "Created a chunk of size 1099, which is longer than the specified 1000\n",
      "Created a chunk of size 1353, which is longer than the specified 1000\n",
      "Created a chunk of size 1473, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1030, which is longer than the specified 1000\n",
      "Created a chunk of size 1504, which is longer than the specified 1000\n",
      "Created a chunk of size 1038, which is longer than the specified 1000\n",
      "Created a chunk of size 1140, which is longer than the specified 1000\n",
      "Created a chunk of size 1276, which is longer than the specified 1000\n",
      "Created a chunk of size 1300, which is longer than the specified 1000\n",
      "Created a chunk of size 1232, which is longer than the specified 1000\n",
      "Created a chunk of size 1221, which is longer than the specified 1000\n",
      "Created a chunk of size 1473, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1058, which is longer than the specified 1000\n",
      "Created a chunk of size 1075, which is longer than the specified 1000\n",
      "Created a chunk of size 1456, which is longer than the specified 1000\n",
      "Created a chunk of size 1181, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 2108, which is longer than the specified 1000\n",
      "Created a chunk of size 1285, which is longer than the specified 1000\n",
      "Created a chunk of size 1236, which is longer than the specified 1000\n",
      "Created a chunk of size 1304, which is longer than the specified 1000\n",
      "Created a chunk of size 1247, which is longer than the specified 1000\n",
      "Created a chunk of size 1010, which is longer than the specified 1000\n",
      "Created a chunk of size 1104, which is longer than the specified 1000\n",
      "Created a chunk of size 1296, which is longer than the specified 1000\n",
      "Created a chunk of size 1919, which is longer than the specified 1000\n",
      "Created a chunk of size 3515, which is longer than the specified 1000\n",
      "Created a chunk of size 1852, which is longer than the specified 1000\n",
      "Created a chunk of size 1533, which is longer than the specified 1000\n",
      "Created a chunk of size 1331, which is longer than the specified 1000\n",
      "Created a chunk of size 2549, which is longer than the specified 1000\n",
      "Created a chunk of size 1696, which is longer than the specified 1000\n",
      "Created a chunk of size 1086, which is longer than the specified 1000\n",
      "Created a chunk of size 1647, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1185, which is longer than the specified 1000\n",
      "Created a chunk of size 1453, which is longer than the specified 1000\n",
      "Created a chunk of size 1300, which is longer than the specified 1000\n",
      "Created a chunk of size 1423, which is longer than the specified 1000\n",
      "Created a chunk of size 1036, which is longer than the specified 1000\n",
      "Created a chunk of size 2005, which is longer than the specified 1000\n",
      "Created a chunk of size 1235, which is longer than the specified 1000\n",
      "Created a chunk of size 1221, which is longer than the specified 1000\n",
      "Created a chunk of size 1197, which is longer than the specified 1000\n",
      "Created a chunk of size 1147, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 1131, which is longer than the specified 1000\n",
      "Created a chunk of size 1227, which is longer than the specified 1000\n",
      "Created a chunk of size 1233, which is longer than the specified 1000\n",
      "Created a chunk of size 1250, which is longer than the specified 1000\n",
      "Created a chunk of size 1092, which is longer than the specified 1000\n",
      "Created a chunk of size 2175, which is longer than the specified 1000\n",
      "Created a chunk of size 1205, which is longer than the specified 1000\n",
      "Created a chunk of size 1583, which is longer than the specified 1000\n",
      "Created a chunk of size 1224, which is longer than the specified 1000\n",
      "Created a chunk of size 2461, which is longer than the specified 1000\n",
      "Created a chunk of size 1048, which is longer than the specified 1000\n",
      "Created a chunk of size 1052, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7114\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "print(f\"{len(texts)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then embed chunks and upload them to the DeepLake.\n",
    "\n",
    "This can take several minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special=set(), chunk_size=1000, max_retries=6, request_timeout=None, headers=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(disallowed_special=())\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain.vectorstores import DeepLake\n",
    "\n",
    "# db = DeepLake.from_documents(texts, embeddings, dataset_path=f\"hub://{DEEPLAKE_ACCOUNT_NAME}/langchain-code\")\n",
    "# db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "vectorstore.save_local(\"vectorstore.faiss\", index_name=\"code\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering\n",
    "First load the dataset, construct the retriever, then construct the Conversational Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# db = DeepLake(dataset_path=f\"hub://{DEEPLAKE_ACCOUNT_NAME}/langchain-code\", read_only=True, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['fetch_k'] = 20\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "retriever.search_kwargs['k'] = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify user defined functions using [Deep Lake filters](https://docs.deeplake.ai/en/latest/deeplake.core.dataset.html#deeplake.core.dataset.Dataset.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter(x):\n",
    "    # filter based on source code\n",
    "    if 'something' in x['text'].data()['value']:\n",
    "        return False\n",
    "    \n",
    "    # filter based on path e.g. extension\n",
    "    metadata =  x['metadata'].data()['value']\n",
    "    return 'only_this' in metadata['source'] or 'also_that' in metadata['source']\n",
    "\n",
    "### turn on below for custom filtering\n",
    "# retriever.search_kwargs['filter'] = filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "model = ChatOpenAI(model_name='gpt-4') # 'ada' 'gpt-3.5-turbo' 'gpt-4',\n",
    "qa = ConversationalRetrievalChain.from_llm(model,\n",
    "                                           retriever=retriever,\n",
    "                                           return_source_documents=True,\n",
    "                                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question', 'chat_history']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['answer', 'source_documents']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'answer'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.input_keys\n",
    "qa.output_keys\n",
    "qa.output_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa2 = RetrievalQA.from_chain_type(llm=model, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True, \n",
    "                                  verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['query']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'query'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['result', 'source_documents']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'result'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa2.input_keys\n",
    "qa2.input_key\n",
    "qa2.output_keys\n",
    "qa2.output_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "-> **Question**: What is the langchain class hierarchy? \n",
      "\n",
      "**Answer**: The LangChain class hierarchy includes various classes and components used to create, manage, and interact with language models, chains, prompts, tools, and other utilities. Here is an overview of the class hierarchy:\n",
      "\n",
      "- Chain (Base class for all chains)\n",
      "  - LLMChain (Language model chain)\n",
      "    - TaskCreationChain\n",
      "    - TaskPrioritizationChain\n",
      "  - LLMBashChain (Language model bash chain)\n",
      "  - LLMCheckerChain (Language model checker chain)\n",
      "  - LLMMathChain (Language model math chain)\n",
      "  - PALChain (PAL chain)\n",
      "  - QAWithSourcesChain (Question answering with sources chain)\n",
      "    - VectorDBQAWithSourcesChain\n",
      "  - VectorDBQA (Retrieval QA chain)\n",
      "  - SQLDatabaseChain (SQL database chain)\n",
      "  - APIChain (API chain)\n",
      "    - OpenAPIEndpointChain\n",
      "  - AnalyzeDocumentChain (Analyze document chain)\n",
      "  - ConstitutionalChain (Constitutional chain)\n",
      "  - ConversationChain (Conversation chain)\n",
      "  - RouterChain (Router chain)\n",
      "    - LLMRouterChain\n",
      "    - MultiRouteChain\n",
      "    - MultiPromptChain\n",
      "    - MultiRetrievalQAChain\n",
      "  - GraphQAChain (Graph QA chain)\n",
      "    - GraphCypherQAChain\n",
      "  - HypotheticalDocumentEmbedder (Hyde chain)\n",
      "  - SequentialChain (Sequential chain)\n",
      "\n",
      "- BaseLanguageModel (Base class for language models)\n",
      "  - AI21\n",
      "  - AlephAlpha\n",
      "  - Anthropic\n",
      "  - Anyscale\n",
      "  - Banana\n",
      "  - Beam\n",
      "  - Bedrock\n",
      "  - CerebriumAI\n",
      "  - Cohere\n",
      "  - CTransformers\n",
      "  - Databricks\n",
      "  - DeepInfra\n",
      "  - FakeListLLM\n",
      "  - ForefrontAI\n",
      "  - GooglePalm\n",
      "  - GooseAI\n",
      "  - GPT4All\n",
      "  - HuggingFaceEndpoint\n",
      "  - HuggingFaceHub\n",
      "  - HuggingFacePipeline\n",
      "  - HuggingFaceTextGenInference\n",
      "  - HumanInputLLM\n",
      "  - LlamaCpp\n",
      "  - Modal\n",
      "  - MosaicML\n",
      "  - NLPCloud\n",
      "  - OpenAI\n",
      "  - OpenAIChat\n",
      "  - OpenLM\n",
      "  - Petals\n",
      "  - PipelineAI\n",
      "  - PredictionGuard\n",
      "  - PromptLayerOpenAI\n",
      "  - PromptLayerOpenAIChat\n",
      "  - Replicate\n",
      "  - RWKV\n",
      "  - SagemakerEndpoint\n",
      "  - SelfHostedPipeline\n",
      "  - SelfHostedHuggingFaceLLM\n",
      "  - StochasticAI\n",
      "  - VertexAI\n",
      "  - Writer\n",
      "\n",
      "- BasePromptTemplate (Base class for prompt templates)\n",
      "  - PromptTemplate\n",
      "  - FewShotPromptTemplate\n",
      "\n",
      "This hierarchy outlines the main classes used to build and manage various chains, language models, and prompts within the LangChain library. Note that there are many other classes and utility functions that are not included in this hierarchy, as they support these main classes in specific tasks and functionalities. \n",
      "\n",
      "**Sources**: [Document(page_content='from langchain.agents import MRKLChain, ReActChain, SelfAskWithSearchChain\\nfrom langchain.cache import BaseCache\\nfrom langchain.chains import (\\n    ConversationChain,\\n    LLMBashChain,\\n    LLMChain,\\n    LLMCheckerChain,\\n    LLMMathChain,\\n    PALChain,\\n    QAWithSourcesChain,\\n    SQLDatabaseChain,\\n    VectorDBQA,\\n    VectorDBQAWithSourcesChain,\\n)\\nfrom langchain.docstore import InMemoryDocstore, Wikipedia\\nfrom langchain.llms import (\\n    Anthropic,\\n    Banana,\\n    CerebriumAI,\\n    Cohere,\\n    ForefrontAI,\\n    GooseAI,\\n    HuggingFaceHub,\\n    HuggingFaceTextGenInference,\\n    LlamaCpp,\\n    Modal,\\n    OpenAI,\\n    Petals,\\n    PipelineAI,\\n    SagemakerEndpoint,\\n    StochasticAI,\\n    Writer,\\n)\\nfrom langchain.llms.huggingface_pipeline import HuggingFacePipeline\\nfrom langchain.prompts import (\\n    BasePromptTemplate,\\n    FewShotPromptTemplate,\\n    Prompt,\\n    PromptTemplate,\\n)\\nfrom langchain.sql_database import SQLDatabase\\nfrom langchain.utilities.arxiv import ArxivAPIWrapper\\nfrom langchain.utilities.google_search import GoogleSearchAPIWrapper\\nfrom langchain.utilities.google_serper import GoogleSerperAPIWrapper\\nfrom langchain.utilities.powerbi import PowerBIDataset\\nfrom langchain.utilities.searx_search import SearxSearchWrapper\\nfrom langchain.utilities.serpapi import SerpAPIWrapper\\nfrom langchain.utilities.wikipedia import WikipediaAPIWrapper\\nfrom langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\\nfrom langchain.vectorstores import FAISS, ElasticVectorSearch', metadata={'source': '../data/langchain/langchain/__init__.py'}), Document(page_content='from langchain.chains.api.base import APIChain\\nfrom langchain.chains.base import Chain\\nfrom langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\\nfrom langchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain\\nfrom langchain.chains.combine_documents.refine import RefineDocumentsChain\\nfrom langchain.chains.combine_documents.stuff import StuffDocumentsChain\\nfrom langchain.chains.hyde.base import HypotheticalDocumentEmbedder\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.chains.llm_bash.base import LLMBashChain\\nfrom langchain.chains.llm_checker.base import LLMCheckerChain\\nfrom langchain.chains.llm_math.base import LLMMathChain\\nfrom langchain.chains.llm_requests import LLMRequestsChain\\nfrom langchain.chains.pal.base import PALChain\\nfrom langchain.chains.qa_with_sources.base import QAWithSourcesChain\\nfrom langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain\\nfrom langchain.chains.retrieval_qa.base import VectorDBQA\\nfrom langchain.chains.sql_database.base import SQLDatabaseChain\\nfrom langchain.llms.loading import load_llm, load_llm_from_config\\nfrom langchain.prompts.loading import load_prompt, load_prompt_from_config\\nfrom langchain.utilities.loading import try_load_from_hub', metadata={'source': '../data/langchain/langchain/chains/loading.py'}), Document(page_content='\"\"\"Chains are easily reusable components which can be linked together.\"\"\"\\nfrom langchain.chains.api.base import APIChain\\nfrom langchain.chains.api.openapi.chain import OpenAPIEndpointChain\\nfrom langchain.chains.combine_documents.base import AnalyzeDocumentChain\\nfrom langchain.chains.constitutional_ai.base import ConstitutionalChain\\nfrom langchain.chains.conversation.base import ConversationChain\\nfrom langchain.chains.conversational_retrieval.base import (\\n    ChatVectorDBChain,\\n    ConversationalRetrievalChain,\\n)\\nfrom langchain.chains.flare.base import FlareChain\\nfrom langchain.chains.graph_qa.base import GraphQAChain\\nfrom langchain.chains.graph_qa.cypher import GraphCypherQAChain\\nfrom langchain.chains.hyde.base import HypotheticalDocumentEmbedder\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.chains.llm_bash.base import LLMBashChain\\nfrom langchain.chains.llm_checker.base import LLMCheckerChain\\nfrom langchain.chains.llm_math.base import LLMMathChain\\nfrom langchain.chains.llm_requests import LLMRequestsChain\\nfrom langchain.chains.llm_summarization_checker.base import LLMSummarizationCheckerChain\\nfrom langchain.chains.loading import load_chain\\nfrom langchain.chains.mapreduce import MapReduceChain\\nfrom langchain.chains.moderation import OpenAIModerationChain\\nfrom langchain.chains.pal.base import PALChain\\nfrom langchain.chains.qa_generation.base import QAGenerationChain\\nfrom langchain.chains.qa_with_sources.base import QAWithSourcesChain\\nfrom langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\\nfrom langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain\\nfrom langchain.chains.retrieval_qa.base import RetrievalQA, VectorDBQA\\nfrom langchain.chains.sequential import SequentialChain, SimpleSequentialChain\\nfrom langchain.chains.sql_database.base import (\\n    SQLDatabaseChain,\\n    SQLDatabaseSequentialChain,\\n)\\nfrom langchain.chains.transform import TransformChain', metadata={'source': '../data/langchain/langchain/chains/__init__.py'}), Document(page_content='import langchain\\nfrom langchain.callbacks.base import (\\n    BaseCallbackHandler,\\n    BaseCallbackManager,\\n    ChainManagerMixin,\\n    LLMManagerMixin,\\n    RunManagerMixin,\\n    ToolManagerMixin,\\n)\\nfrom langchain.callbacks.openai_info import OpenAICallbackHandler\\nfrom langchain.callbacks.stdout import StdOutCallbackHandler\\nfrom langchain.callbacks.tracers.langchain import LangChainTracer\\nfrom langchain.callbacks.tracers.langchain_v1 import LangChainTracerV1, TracerSessionV1\\nfrom langchain.callbacks.tracers.schemas import TracerSession\\nfrom langchain.callbacks.tracers.stdout import ConsoleCallbackHandler\\nfrom langchain.callbacks.tracers.wandb import WandbTracer\\nfrom langchain.schema import (\\n    AgentAction,\\n    AgentFinish,\\n    BaseMessage,\\n    LLMResult,\\n    get_buffer_string,\\n)\\n\\nlogger = logging.getLogger(__name__)\\nCallbacks = Optional[Union[List[BaseCallbackHandler], BaseCallbackManager]]', metadata={'source': '../data/langchain/langchain/callbacks/manager.py'}), Document(page_content='\"\"\"Base interface that all chains should implement.\"\"\"\\nimport inspect\\nimport json\\nimport warnings\\nfrom abc import ABC, abstractmethod\\nfrom pathlib import Path\\nfrom typing import Any, Dict, List, Optional, Union\\n\\nimport yaml\\nfrom pydantic import BaseModel, Field, root_validator, validator\\n\\nimport langchain\\nfrom langchain.callbacks.base import BaseCallbackManager\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManager,\\n    AsyncCallbackManagerForChainRun,\\n    CallbackManager,\\n    CallbackManagerForChainRun,\\n    Callbacks,\\n)\\nfrom langchain.schema import BaseMemory\\n\\n\\ndef _get_verbosity() -> bool:\\n    return langchain.verbose\\n\\n\\nclass Chain(BaseModel, ABC):\\n    \"\"\"Base interface that all chains should implement.\"\"\"', metadata={'source': '../data/langchain/langchain/chains/base.py'}), Document(page_content='from langchain import LLMChain, PromptTemplate\\nfrom langchain.base_language import BaseLanguageModel\\n\\n\\nclass TaskPrioritizationChain(LLMChain):\\n    \"\"\"Chain to prioritize tasks.\"\"\"', metadata={'source': '../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_prioritization.py'}), Document(page_content='from langchain.llms.ai21 import AI21\\nfrom langchain.llms.aleph_alpha import AlephAlpha\\nfrom langchain.llms.anthropic import Anthropic\\nfrom langchain.llms.anyscale import Anyscale\\nfrom langchain.llms.bananadev import Banana\\nfrom langchain.llms.base import BaseLLM\\nfrom langchain.llms.beam import Beam\\nfrom langchain.llms.bedrock import Bedrock\\nfrom langchain.llms.cerebriumai import CerebriumAI\\nfrom langchain.llms.cohere import Cohere\\nfrom langchain.llms.ctransformers import CTransformers\\nfrom langchain.llms.databricks import Databricks\\nfrom langchain.llms.deepinfra import DeepInfra\\nfrom langchain.llms.fake import FakeListLLM\\nfrom langchain.llms.forefrontai import ForefrontAI\\nfrom langchain.llms.google_palm import GooglePalm\\nfrom langchain.llms.gooseai import GooseAI\\nfrom langchain.llms.gpt4all import GPT4All\\nfrom langchain.llms.huggingface_endpoint import HuggingFaceEndpoint\\nfrom langchain.llms.huggingface_hub import HuggingFaceHub\\nfrom langchain.llms.huggingface_pipeline import HuggingFacePipeline\\nfrom langchain.llms.huggingface_text_gen_inference import HuggingFaceTextGenInference\\nfrom langchain.llms.human import HumanInputLLM\\nfrom langchain.llms.llamacpp import LlamaCpp\\nfrom langchain.llms.modal import Modal\\nfrom langchain.llms.mosaicml import MosaicML\\nfrom langchain.llms.nlpcloud import NLPCloud\\nfrom langchain.llms.openai import AzureOpenAI, OpenAI, OpenAIChat\\nfrom langchain.llms.openlm import OpenLM\\nfrom langchain.llms.petals import Petals\\nfrom langchain.llms.pipelineai import PipelineAI\\nfrom langchain.llms.predictionguard import PredictionGuard\\nfrom langchain.llms.promptlayer_openai import PromptLayerOpenAI, PromptLayerOpenAIChat\\nfrom langchain.llms.replicate import Replicate\\nfrom langchain.llms.rwkv import RWKV\\nfrom langchain.llms.sagemaker_endpoint import SagemakerEndpoint\\nfrom langchain.llms.self_hosted import SelfHostedPipeline\\nfrom langchain.llms.self_hosted_hugging_face import SelfHostedHuggingFaceLLM\\nfrom langchain.llms.stochasticai import StochasticAI\\nfrom langchain.llms.vertexai import VertexAI\\nfrom langchain.llms.writer import Writer', metadata={'source': '../data/langchain/langchain/llms/__init__.py'}), Document(page_content='\"\"\"Tests for correct functioning of chains.\"\"\"', metadata={'source': '../data/langchain/tests/unit_tests/chains/__init__.py'}), Document(page_content='from langchain.chains.router.base import MultiRouteChain, RouterChain\\nfrom langchain.chains.router.llm_router import LLMRouterChain\\nfrom langchain.chains.router.multi_prompt import MultiPromptChain\\nfrom langchain.chains.router.multi_retrieval_qa import MultiRetrievalQAChain\\n\\n__all__ = [\\n    \"RouterChain\",\\n    \"MultiRouteChain\",\\n    \"MultiPromptChain\",\\n    \"MultiRetrievalQAChain\",\\n    \"LLMRouterChain\",\\n]', metadata={'source': '../data/langchain/langchain/chains/router/__init__.py'}), Document(page_content='@property\\n    def _chain_type(self) -> str:\\n        return \"llm_bash_chain\"', metadata={'source': '../data/langchain/langchain/chains/llm_bash/base.py'}), Document(page_content='\"\"\"Chain for applying constitutional principles to the outputs of another chain.\"\"\"\\nfrom typing import Any, Dict, List, Optional\\n\\nfrom langchain.base_language import BaseLanguageModel\\nfrom langchain.callbacks.manager import CallbackManagerForChainRun\\nfrom langchain.chains.base import Chain\\nfrom langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\\nfrom langchain.chains.constitutional_ai.principles import PRINCIPLES\\nfrom langchain.chains.constitutional_ai.prompts import CRITIQUE_PROMPT, REVISION_PROMPT\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.prompts.base import BasePromptTemplate\\n\\n\\nclass ConstitutionalChain(Chain):\\n    \"\"\"Chain for applying constitutional principles.\\n\\n    Example:\\n        .. code-block:: python\\n\\n            from langchain.llms import OpenAI\\n            from langchain.chains import LLMChain, ConstitutionalChain\\n            from langchain.chains.constitutional_ai.models \\\\\\n                import ConstitutionalPrinciple', metadata={'source': '../data/langchain/langchain/chains/constitutional_ai/base.py'}), Document(page_content='\"\"\"LangChain+ Client.\"\"\"\\n\\n\\nfrom langchain.client.langchain import LangChainPlusClient\\n\\n__all__ = [\"LangChainPlusClient\"]', metadata={'source': '../data/langchain/langchain/client/__init__.py'}), Document(page_content='@property\\n    def _chain_type(self) -> str:\\n        return \"llm_bash_chain\"\\n\\n    @classmethod\\n    def from_llm(\\n        cls,\\n        llm: BaseLanguageModel,\\n        prompt: BasePromptTemplate = PROMPT,\\n        **kwargs: Any,\\n    ) -> LLMBashChain:\\n        llm_chain = LLMChain(llm=llm, prompt=prompt)\\n        return cls(llm_chain=llm_chain, **kwargs)', metadata={'source': '../data/langchain/langchain/chains/llm_bash/base.py'}), Document(page_content='@property\\n    def _chain_type(self) -> str:\\n        return \"llm_chain\"\\n\\n    @classmethod\\n    def from_string(cls, llm: BaseLanguageModel, template: str) -> Chain:\\n        \"\"\"Create LLMChain from LLM and template.\"\"\"\\n        prompt_template = PromptTemplate.from_template(template)\\n        return cls(llm=llm, prompt=prompt_template)', metadata={'source': '../data/langchain/langchain/chains/llm.py'}), Document(page_content='\"\"\"Callback handlers that allow listening to events in LangChain.\"\"\"\\n\\nfrom langchain.callbacks.aim_callback import AimCallbackHandler\\nfrom langchain.callbacks.clearml_callback import ClearMLCallbackHandler\\nfrom langchain.callbacks.comet_ml_callback import CometCallbackHandler\\nfrom langchain.callbacks.manager import (\\n    get_openai_callback,\\n    tracing_enabled,\\n    wandb_tracing_enabled,\\n)\\nfrom langchain.callbacks.mlflow_callback import MlflowCallbackHandler\\nfrom langchain.callbacks.openai_info import OpenAICallbackHandler\\nfrom langchain.callbacks.stdout import StdOutCallbackHandler\\nfrom langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler\\nfrom langchain.callbacks.wandb_callback import WandbCallbackHandler\\nfrom langchain.callbacks.whylabs_callback import WhyLabsCallbackHandler', metadata={'source': '../data/langchain/langchain/callbacks/__init__.py'}), Document(page_content='from langchain.agents.tools import Tool\\nfrom langchain.base_language import BaseLanguageModel\\nfrom langchain.callbacks.base import BaseCallbackManager\\nfrom langchain.callbacks.manager import Callbacks\\nfrom langchain.chains.api import news_docs, open_meteo_docs, podcast_docs, tmdb_docs\\nfrom langchain.chains.api.base import APIChain\\nfrom langchain.chains.llm_math.base import LLMMathChain\\nfrom langchain.chains.pal.base import PALChain\\nfrom langchain.requests import TextRequestsWrapper\\nfrom langchain.tools.arxiv.tool import ArxivQueryRun\\nfrom langchain.tools.base import BaseTool\\nfrom langchain.tools.bing_search.tool import BingSearchRun\\nfrom langchain.tools.ddg_search.tool import DuckDuckGoSearchRun\\nfrom langchain.tools.google_search.tool import GoogleSearchResults, GoogleSearchRun\\nfrom langchain.tools.metaphor_search.tool import MetaphorSearchResults\\nfrom langchain.tools.google_serper.tool import GoogleSerperResults, GoogleSerperRun\\nfrom langchain.tools.graphql.tool import BaseGraphQLTool\\nfrom langchain.tools.human.tool import HumanInputRun\\nfrom langchain.tools.python.tool import PythonREPLTool\\nfrom langchain.tools.requests.tool import (\\n    RequestsDeleteTool,\\n    RequestsGetTool,\\n    RequestsPatchTool,\\n    RequestsPostTool,\\n    RequestsPutTool,\\n)\\nfrom langchain.tools.scenexplain.tool import SceneXplainTool\\nfrom langchain.tools.searx_search.tool import SearxSearchResults, SearxSearchRun\\nfrom langchain.tools.shell.tool import ShellTool\\nfrom langchain.tools.wikipedia.tool import WikipediaQueryRun\\nfrom langchain.tools.wolfram_alpha.tool import WolframAlphaQueryRun\\nfrom langchain.tools.openweathermap.tool import OpenWeatherMapQueryRun\\nfrom langchain.utilities import ArxivAPIWrapper\\nfrom langchain.utilities.bing_search import BingSearchAPIWrapper\\nfrom langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\\nfrom langchain.utilities.google_search import GoogleSearchAPIWrapper\\nfrom langchain.utilities.google_serper import GoogleSerperAPIWrapper\\nfrom langchain.utilities.metaphor_search import MetaphorSearchAPIWrapper\\nfrom langchain.utilities.awslambda import LambdaWrapper\\nfrom langchain.utilities.graphql import GraphQLAPIWrapper\\nfrom langchain.utilities.searx_search import SearxSearchWrapper\\nfrom langchain.utilities.serpapi import SerpAPIWrapper\\nfrom langchain.utilities.twilio import TwilioAPIWrapper\\nfrom langchain.utilities.wikipedia import WikipediaAPIWrapper\\nfrom langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\\nfrom langchain.utilities.openweathermap import OpenWeatherMapAPIWrapper', metadata={'source': '../data/langchain/langchain/agents/load_tools.py'}), Document(page_content='@property\\n    def _chain_type(self) -> str:\\n        return \"llm_checker_chain\"\\n\\n    @classmethod\\n    def from_llm(\\n        cls,\\n        llm: BaseLanguageModel,\\n        create_draft_answer_prompt: PromptTemplate = CREATE_DRAFT_ANSWER_PROMPT,\\n        list_assertions_prompt: PromptTemplate = LIST_ASSERTIONS_PROMPT,\\n        check_assertions_prompt: PromptTemplate = CHECK_ASSERTIONS_PROMPT,\\n        revised_answer_prompt: PromptTemplate = REVISED_ANSWER_PROMPT,\\n        **kwargs: Any,\\n    ) -> LLMCheckerChain:\\n        question_to_checked_assertions_chain = (\\n            _load_question_to_checked_assertions_chain(\\n                llm,\\n                create_draft_answer_prompt,\\n                list_assertions_prompt,\\n                check_assertions_prompt,\\n                revised_answer_prompt,\\n            )\\n        )\\n        return cls(\\n            question_to_checked_assertions_chain=question_to_checked_assertions_chain,\\n            **kwargs,\\n        )', metadata={'source': '../data/langchain/langchain/chains/llm_checker/base.py'}), Document(page_content='\"\"\"Chain for chatting with a vector database.\"\"\"\\nfrom __future__ import annotations\\n\\nimport warnings\\nfrom abc import abstractmethod\\nfrom pathlib import Path\\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Union\\n\\nfrom pydantic import Extra, Field, root_validator\\n\\nfrom langchain.base_language import BaseLanguageModel\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForChainRun,\\n    CallbackManagerForChainRun,\\n)\\nfrom langchain.chains.base import Chain\\nfrom langchain.chains.combine_documents.base import BaseCombineDocumentsChain\\nfrom langchain.chains.combine_documents.stuff import StuffDocumentsChain\\nfrom langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.chains.question_answering import load_qa_chain\\nfrom langchain.prompts.base import BasePromptTemplate\\nfrom langchain.schema import BaseMessage, BaseRetriever, Document\\nfrom langchain.vectorstores.base import VectorStore', metadata={'source': '../data/langchain/langchain/chains/conversational_retrieval/base.py'}), Document(page_content='from langchain import LLMChain, PromptTemplate\\nfrom langchain.base_language import BaseLanguageModel\\n\\n\\nclass TaskCreationChain(LLMChain):\\n    \"\"\"Chain to generates tasks.\"\"\"', metadata={'source': '../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_creation.py'}), Document(page_content='class TaskPrioritizationChain(LLMChain):\\n    \"\"\"Chain to prioritize tasks.\"\"\"\\n\\n    @classmethod\\n    def from_llm(cls, llm: BaseLanguageModel, verbose: bool = True) -> LLMChain:\\n        \"\"\"Get the response parser.\"\"\"\\n        task_prioritization_template = (\\n            \"You are a task prioritization AI tasked with cleaning the formatting of \"\\n            \"and reprioritizing the following tasks: {task_names}.\"\\n            \" Consider the ultimate objective of your team: {objective}.\"\\n            \" Do not remove any tasks. Return the result as a numbered list, like:\"\\n            \" #. First task\"\\n            \" #. Second task\"\\n            \" Start the task list with number {next_task_id}.\"\\n        )\\n        prompt = PromptTemplate(\\n            template=task_prioritization_template,\\n            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\\n        )\\n        return cls(prompt=prompt, llm=llm, verbose=verbose)', metadata={'source': '../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_prioritization.py'})] \n",
      "\n",
      "0: ../data/langchain/langchain/__init__.py \n",
      "\n",
      "from langchain.agents import MRKLChain, ReActChain, SelfAskWithSearchChain\n",
      "from langchain.cache import BaseCache\n",
      "from langchain.chains import (\n",
      "    ConversationChain,\n",
      "    LLMBashChain,\n",
      "    LLMChain,\n",
      "    LLMCheckerChain,\n",
      "    LLMMathChain,\n",
      "    PALChain,\n",
      "    QAWithSourcesChain,\n",
      "    SQLDatabaseChain,\n",
      "    VectorDBQA,\n",
      "    VectorDBQAWithSourcesChain,\n",
      ")\n",
      "from langchain.docstore import InMemoryDocstore, Wikipedia\n",
      "from langchain.llms import (\n",
      "    Anthropic,\n",
      "    Banana,\n",
      "    CerebriumAI,\n",
      "    Cohere,\n",
      "    ForefrontAI,\n",
      "    GooseAI,\n",
      "    HuggingFaceHub,\n",
      "    HuggingFaceTextGenInference,\n",
      "    LlamaCpp,\n",
      "    Modal,\n",
      "    OpenAI,\n",
      "    Petals,\n",
      "    PipelineAI,\n",
      "    SagemakerEndpoint,\n",
      "    StochasticAI,\n",
      "    Writer,\n",
      ")\n",
      "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
      "from langchain.prompts import (\n",
      "    BasePromptTemplate,\n",
      "    FewShotPromptTemplate,\n",
      "    Prompt,\n",
      "    PromptTemplate,\n",
      ")\n",
      "from langchain.sql_database import SQLDatabase\n",
      "from langchain.utilities.arxiv import ArxivAPIWrapper\n",
      "from langchain.utilities.google_search import GoogleSearchAPIWrapper\n",
      "from langchain.utilities.google_serper import GoogleSerperAPIWrapper\n",
      "from langchain.utilities.powerbi import PowerBIDataset\n",
      "from langchain.utilities.searx_search import SearxSearchWrapper\n",
      "from langchain.utilities.serpapi import SerpAPIWrapper\n",
      "from langchain.utilities.wikipedia import WikipediaAPIWrapper\n",
      "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
      "from langchain.vectorstores import FAISS, ElasticVectorSearch \n",
      "\n",
      "\n",
      "1: ../data/langchain/langchain/chains/loading.py \n",
      "\n",
      "from langchain.chains.api.base import APIChain\n",
      "from langchain.chains.base import Chain\n",
      "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\n",
      "from langchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain\n",
      "from langchain.chains.combine_documents.refine import RefineDocumentsChain\n",
      "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
      "from langchain.chains.hyde.base import HypotheticalDocumentEmbedder\n",
      "from langchain.chains.llm import LLMChain\n",
      "from langchain.chains.llm_bash.base import LLMBashChain\n",
      "from langchain.chains.llm_checker.base import LLMCheckerChain\n",
      "from langchain.chains.llm_math.base import LLMMathChain\n",
      "from langchain.chains.llm_requests import LLMRequestsChain\n",
      "from langchain.chains.pal.base import PALChain\n",
      "from langchain.chains.qa_with_sources.base import QAWithSourcesChain\n",
      "from langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain\n",
      "from langchain.chains.retrieval_qa.base import VectorDBQA\n",
      "from langchain.chains.sql_database.base import SQLDatabaseChain\n",
      "from langchain.llms.loading import load_llm, load_llm_from_config\n",
      "from langchain.prompts.loading import load_prompt, load_prompt_from_config\n",
      "from langchain.utilities.loading import try_load_from_hub \n",
      "\n",
      "\n",
      "2: ../data/langchain/langchain/chains/__init__.py \n",
      "\n",
      "\"\"\"Chains are easily reusable components which can be linked together.\"\"\"\n",
      "from langchain.chains.api.base import APIChain\n",
      "from langchain.chains.api.openapi.chain import OpenAPIEndpointChain\n",
      "from langchain.chains.combine_documents.base import AnalyzeDocumentChain\n",
      "from langchain.chains.constitutional_ai.base import ConstitutionalChain\n",
      "from langchain.chains.conversation.base import ConversationChain\n",
      "from langchain.chains.conversational_retrieval.base import (\n",
      "    ChatVectorDBChain,\n",
      "    ConversationalRetrievalChain,\n",
      ")\n",
      "from langchain.chains.flare.base import FlareChain\n",
      "from langchain.chains.graph_qa.base import GraphQAChain\n",
      "from langchain.chains.graph_qa.cypher import GraphCypherQAChain\n",
      "from langchain.chains.hyde.base import HypotheticalDocumentEmbedder\n",
      "from langchain.chains.llm import LLMChain\n",
      "from langchain.chains.llm_bash.base import LLMBashChain\n",
      "from langchain.chains.llm_checker.base import LLMCheckerChain\n",
      "from langchain.chains.llm_math.base import LLMMathChain\n",
      "from langchain.chains.llm_requests import LLMRequestsChain\n",
      "from langchain.chains.llm_summarization_checker.base import LLMSummarizationCheckerChain\n",
      "from langchain.chains.loading import load_chain\n",
      "from langchain.chains.mapreduce import MapReduceChain\n",
      "from langchain.chains.moderation import OpenAIModerationChain\n",
      "from langchain.chains.pal.base import PALChain\n",
      "from langchain.chains.qa_generation.base import QAGenerationChain\n",
      "from langchain.chains.qa_with_sources.base import QAWithSourcesChain\n",
      "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
      "from langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain\n",
      "from langchain.chains.retrieval_qa.base import RetrievalQA, VectorDBQA\n",
      "from langchain.chains.sequential import SequentialChain, SimpleSequentialChain\n",
      "from langchain.chains.sql_database.base import (\n",
      "    SQLDatabaseChain,\n",
      "    SQLDatabaseSequentialChain,\n",
      ")\n",
      "from langchain.chains.transform import TransformChain \n",
      "\n",
      "\n",
      "3: ../data/langchain/langchain/callbacks/manager.py \n",
      "\n",
      "import langchain\n",
      "from langchain.callbacks.base import (\n",
      "    BaseCallbackHandler,\n",
      "    BaseCallbackManager,\n",
      "    ChainManagerMixin,\n",
      "    LLMManagerMixin,\n",
      "    RunManagerMixin,\n",
      "    ToolManagerMixin,\n",
      ")\n",
      "from langchain.callbacks.openai_info import OpenAICallbackHandler\n",
      "from langchain.callbacks.stdout import StdOutCallbackHandler\n",
      "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
      "from langchain.callbacks.tracers.langchain_v1 import LangChainTracerV1, TracerSessionV1\n",
      "from langchain.callbacks.tracers.schemas import TracerSession\n",
      "from langchain.callbacks.tracers.stdout import ConsoleCallbackHandler\n",
      "from langchain.callbacks.tracers.wandb import WandbTracer\n",
      "from langchain.schema import (\n",
      "    AgentAction,\n",
      "    AgentFinish,\n",
      "    BaseMessage,\n",
      "    LLMResult,\n",
      "    get_buffer_string,\n",
      ")\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "Callbacks = Optional[Union[List[BaseCallbackHandler], BaseCallbackManager]] \n",
      "\n",
      "\n",
      "4: ../data/langchain/langchain/chains/base.py \n",
      "\n",
      "\"\"\"Base interface that all chains should implement.\"\"\"\n",
      "import inspect\n",
      "import json\n",
      "import warnings\n",
      "from abc import ABC, abstractmethod\n",
      "from pathlib import Path\n",
      "from typing import Any, Dict, List, Optional, Union\n",
      "\n",
      "import yaml\n",
      "from pydantic import BaseModel, Field, root_validator, validator\n",
      "\n",
      "import langchain\n",
      "from langchain.callbacks.base import BaseCallbackManager\n",
      "from langchain.callbacks.manager import (\n",
      "    AsyncCallbackManager,\n",
      "    AsyncCallbackManagerForChainRun,\n",
      "    CallbackManager,\n",
      "    CallbackManagerForChainRun,\n",
      "    Callbacks,\n",
      ")\n",
      "from langchain.schema import BaseMemory\n",
      "\n",
      "\n",
      "def _get_verbosity() -> bool:\n",
      "    return langchain.verbose\n",
      "\n",
      "\n",
      "class Chain(BaseModel, ABC):\n",
      "    \"\"\"Base interface that all chains should implement.\"\"\" \n",
      "\n",
      "\n",
      "5: ../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_prioritization.py \n",
      "\n",
      "from langchain import LLMChain, PromptTemplate\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "\n",
      "\n",
      "class TaskPrioritizationChain(LLMChain):\n",
      "    \"\"\"Chain to prioritize tasks.\"\"\" \n",
      "\n",
      "\n",
      "6: ../data/langchain/langchain/llms/__init__.py \n",
      "\n",
      "from langchain.llms.ai21 import AI21\n",
      "from langchain.llms.aleph_alpha import AlephAlpha\n",
      "from langchain.llms.anthropic import Anthropic\n",
      "from langchain.llms.anyscale import Anyscale\n",
      "from langchain.llms.bananadev import Banana\n",
      "from langchain.llms.base import BaseLLM\n",
      "from langchain.llms.beam import Beam\n",
      "from langchain.llms.bedrock import Bedrock\n",
      "from langchain.llms.cerebriumai import CerebriumAI\n",
      "from langchain.llms.cohere import Cohere\n",
      "from langchain.llms.ctransformers import CTransformers\n",
      "from langchain.llms.databricks import Databricks\n",
      "from langchain.llms.deepinfra import DeepInfra\n",
      "from langchain.llms.fake import FakeListLLM\n",
      "from langchain.llms.forefrontai import ForefrontAI\n",
      "from langchain.llms.google_palm import GooglePalm\n",
      "from langchain.llms.gooseai import GooseAI\n",
      "from langchain.llms.gpt4all import GPT4All\n",
      "from langchain.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
      "from langchain.llms.huggingface_hub import HuggingFaceHub\n",
      "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
      "from langchain.llms.huggingface_text_gen_inference import HuggingFaceTextGenInference\n",
      "from langchain.llms.human import HumanInputLLM\n",
      "from langchain.llms.llamacpp import LlamaCpp\n",
      "from langchain.llms.modal import Modal\n",
      "from langchain.llms.mosaicml import MosaicML\n",
      "from langchain.llms.nlpcloud import NLPCloud\n",
      "from langchain.llms.openai import AzureOpenAI, OpenAI, OpenAIChat\n",
      "from langchain.llms.openlm import OpenLM\n",
      "from langchain.llms.petals import Petals\n",
      "from langchain.llms.pipelineai import PipelineAI\n",
      "from langchain.llms.predictionguard import PredictionGuard\n",
      "from langchain.llms.promptlayer_openai import PromptLayerOpenAI, PromptLayerOpenAIChat\n",
      "from langchain.llms.replicate import Replicate\n",
      "from langchain.llms.rwkv import RWKV\n",
      "from langchain.llms.sagemaker_endpoint import SagemakerEndpoint\n",
      "from langchain.llms.self_hosted import SelfHostedPipeline\n",
      "from langchain.llms.self_hosted_hugging_face import SelfHostedHuggingFaceLLM\n",
      "from langchain.llms.stochasticai import StochasticAI\n",
      "from langchain.llms.vertexai import VertexAI\n",
      "from langchain.llms.writer import Writer \n",
      "\n",
      "\n",
      "7: ../data/langchain/tests/unit_tests/chains/__init__.py \n",
      "\n",
      "\"\"\"Tests for correct functioning of chains.\"\"\" \n",
      "\n",
      "\n",
      "8: ../data/langchain/langchain/chains/router/__init__.py \n",
      "\n",
      "from langchain.chains.router.base import MultiRouteChain, RouterChain\n",
      "from langchain.chains.router.llm_router import LLMRouterChain\n",
      "from langchain.chains.router.multi_prompt import MultiPromptChain\n",
      "from langchain.chains.router.multi_retrieval_qa import MultiRetrievalQAChain\n",
      "\n",
      "__all__ = [\n",
      "    \"RouterChain\",\n",
      "    \"MultiRouteChain\",\n",
      "    \"MultiPromptChain\",\n",
      "    \"MultiRetrievalQAChain\",\n",
      "    \"LLMRouterChain\",\n",
      "] \n",
      "\n",
      "\n",
      "9: ../data/langchain/langchain/chains/llm_bash/base.py \n",
      "\n",
      "@property\n",
      "    def _chain_type(self) -> str:\n",
      "        return \"llm_bash_chain\" \n",
      "\n",
      "\n",
      "10: ../data/langchain/langchain/chains/constitutional_ai/base.py \n",
      "\n",
      "\"\"\"Chain for applying constitutional principles to the outputs of another chain.\"\"\"\n",
      "from typing import Any, Dict, List, Optional\n",
      "\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
      "from langchain.chains.base import Chain\n",
      "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
      "from langchain.chains.constitutional_ai.principles import PRINCIPLES\n",
      "from langchain.chains.constitutional_ai.prompts import CRITIQUE_PROMPT, REVISION_PROMPT\n",
      "from langchain.chains.llm import LLMChain\n",
      "from langchain.prompts.base import BasePromptTemplate\n",
      "\n",
      "\n",
      "class ConstitutionalChain(Chain):\n",
      "    \"\"\"Chain for applying constitutional principles.\n",
      "\n",
      "    Example:\n",
      "        .. code-block:: python\n",
      "\n",
      "            from langchain.llms import OpenAI\n",
      "            from langchain.chains import LLMChain, ConstitutionalChain\n",
      "            from langchain.chains.constitutional_ai.models \\\n",
      "                import ConstitutionalPrinciple \n",
      "\n",
      "\n",
      "11: ../data/langchain/langchain/client/__init__.py \n",
      "\n",
      "\"\"\"LangChain+ Client.\"\"\"\n",
      "\n",
      "\n",
      "from langchain.client.langchain import LangChainPlusClient\n",
      "\n",
      "__all__ = [\"LangChainPlusClient\"] \n",
      "\n",
      "\n",
      "12: ../data/langchain/langchain/chains/llm_bash/base.py \n",
      "\n",
      "@property\n",
      "    def _chain_type(self) -> str:\n",
      "        return \"llm_bash_chain\"\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm(\n",
      "        cls,\n",
      "        llm: BaseLanguageModel,\n",
      "        prompt: BasePromptTemplate = PROMPT,\n",
      "        **kwargs: Any,\n",
      "    ) -> LLMBashChain:\n",
      "        llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "        return cls(llm_chain=llm_chain, **kwargs) \n",
      "\n",
      "\n",
      "13: ../data/langchain/langchain/chains/llm.py \n",
      "\n",
      "@property\n",
      "    def _chain_type(self) -> str:\n",
      "        return \"llm_chain\"\n",
      "\n",
      "    @classmethod\n",
      "    def from_string(cls, llm: BaseLanguageModel, template: str) -> Chain:\n",
      "        \"\"\"Create LLMChain from LLM and template.\"\"\"\n",
      "        prompt_template = PromptTemplate.from_template(template)\n",
      "        return cls(llm=llm, prompt=prompt_template) \n",
      "\n",
      "\n",
      "14: ../data/langchain/langchain/callbacks/__init__.py \n",
      "\n",
      "\"\"\"Callback handlers that allow listening to events in LangChain.\"\"\"\n",
      "\n",
      "from langchain.callbacks.aim_callback import AimCallbackHandler\n",
      "from langchain.callbacks.clearml_callback import ClearMLCallbackHandler\n",
      "from langchain.callbacks.comet_ml_callback import CometCallbackHandler\n",
      "from langchain.callbacks.manager import (\n",
      "    get_openai_callback,\n",
      "    tracing_enabled,\n",
      "    wandb_tracing_enabled,\n",
      ")\n",
      "from langchain.callbacks.mlflow_callback import MlflowCallbackHandler\n",
      "from langchain.callbacks.openai_info import OpenAICallbackHandler\n",
      "from langchain.callbacks.stdout import StdOutCallbackHandler\n",
      "from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler\n",
      "from langchain.callbacks.wandb_callback import WandbCallbackHandler\n",
      "from langchain.callbacks.whylabs_callback import WhyLabsCallbackHandler \n",
      "\n",
      "\n",
      "15: ../data/langchain/langchain/agents/load_tools.py \n",
      "\n",
      "from langchain.agents.tools import Tool\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "from langchain.callbacks.base import BaseCallbackManager\n",
      "from langchain.callbacks.manager import Callbacks\n",
      "from langchain.chains.api import news_docs, open_meteo_docs, podcast_docs, tmdb_docs\n",
      "from langchain.chains.api.base import APIChain\n",
      "from langchain.chains.llm_math.base import LLMMathChain\n",
      "from langchain.chains.pal.base import PALChain\n",
      "from langchain.requests import TextRequestsWrapper\n",
      "from langchain.tools.arxiv.tool import ArxivQueryRun\n",
      "from langchain.tools.base import BaseTool\n",
      "from langchain.tools.bing_search.tool import BingSearchRun\n",
      "from langchain.tools.ddg_search.tool import DuckDuckGoSearchRun\n",
      "from langchain.tools.google_search.tool import GoogleSearchResults, GoogleSearchRun\n",
      "from langchain.tools.metaphor_search.tool import MetaphorSearchResults\n",
      "from langchain.tools.google_serper.tool import GoogleSerperResults, GoogleSerperRun\n",
      "from langchain.tools.graphql.tool import BaseGraphQLTool\n",
      "from langchain.tools.human.tool import HumanInputRun\n",
      "from langchain.tools.python.tool import PythonREPLTool\n",
      "from langchain.tools.requests.tool import (\n",
      "    RequestsDeleteTool,\n",
      "    RequestsGetTool,\n",
      "    RequestsPatchTool,\n",
      "    RequestsPostTool,\n",
      "    RequestsPutTool,\n",
      ")\n",
      "from langchain.tools.scenexplain.tool import SceneXplainTool\n",
      "from langchain.tools.searx_search.tool import SearxSearchResults, SearxSearchRun\n",
      "from langchain.tools.shell.tool import ShellTool\n",
      "from langchain.tools.wikipedia.tool import WikipediaQueryRun\n",
      "from langchain.tools.wolfram_alpha.tool import WolframAlphaQueryRun\n",
      "from langchain.tools.openweathermap.tool import OpenWeatherMapQueryRun\n",
      "from langchain.utilities import ArxivAPIWrapper\n",
      "from langchain.utilities.bing_search import BingSearchAPIWrapper\n",
      "from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
      "from langchain.utilities.google_search import GoogleSearchAPIWrapper\n",
      "from langchain.utilities.google_serper import GoogleSerperAPIWrapper\n",
      "from langchain.utilities.metaphor_search import MetaphorSearchAPIWrapper\n",
      "from langchain.utilities.awslambda import LambdaWrapper\n",
      "from langchain.utilities.graphql import GraphQLAPIWrapper\n",
      "from langchain.utilities.searx_search import SearxSearchWrapper\n",
      "from langchain.utilities.serpapi import SerpAPIWrapper\n",
      "from langchain.utilities.twilio import TwilioAPIWrapper\n",
      "from langchain.utilities.wikipedia import WikipediaAPIWrapper\n",
      "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
      "from langchain.utilities.openweathermap import OpenWeatherMapAPIWrapper \n",
      "\n",
      "\n",
      "16: ../data/langchain/langchain/chains/llm_checker/base.py \n",
      "\n",
      "@property\n",
      "    def _chain_type(self) -> str:\n",
      "        return \"llm_checker_chain\"\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm(\n",
      "        cls,\n",
      "        llm: BaseLanguageModel,\n",
      "        create_draft_answer_prompt: PromptTemplate = CREATE_DRAFT_ANSWER_PROMPT,\n",
      "        list_assertions_prompt: PromptTemplate = LIST_ASSERTIONS_PROMPT,\n",
      "        check_assertions_prompt: PromptTemplate = CHECK_ASSERTIONS_PROMPT,\n",
      "        revised_answer_prompt: PromptTemplate = REVISED_ANSWER_PROMPT,\n",
      "        **kwargs: Any,\n",
      "    ) -> LLMCheckerChain:\n",
      "        question_to_checked_assertions_chain = (\n",
      "            _load_question_to_checked_assertions_chain(\n",
      "                llm,\n",
      "                create_draft_answer_prompt,\n",
      "                list_assertions_prompt,\n",
      "                check_assertions_prompt,\n",
      "                revised_answer_prompt,\n",
      "            )\n",
      "        )\n",
      "        return cls(\n",
      "            question_to_checked_assertions_chain=question_to_checked_assertions_chain,\n",
      "            **kwargs,\n",
      "        ) \n",
      "\n",
      "\n",
      "17: ../data/langchain/langchain/chains/conversational_retrieval/base.py \n",
      "\n",
      "\"\"\"Chain for chatting with a vector database.\"\"\"\n",
      "from __future__ import annotations\n",
      "\n",
      "import warnings\n",
      "from abc import abstractmethod\n",
      "from pathlib import Path\n",
      "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
      "\n",
      "from pydantic import Extra, Field, root_validator\n",
      "\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "from langchain.callbacks.manager import (\n",
      "    AsyncCallbackManagerForChainRun,\n",
      "    CallbackManagerForChainRun,\n",
      ")\n",
      "from langchain.chains.base import Chain\n",
      "from langchain.chains.combine_documents.base import BaseCombineDocumentsChain\n",
      "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
      "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
      "from langchain.chains.llm import LLMChain\n",
      "from langchain.chains.question_answering import load_qa_chain\n",
      "from langchain.prompts.base import BasePromptTemplate\n",
      "from langchain.schema import BaseMessage, BaseRetriever, Document\n",
      "from langchain.vectorstores.base import VectorStore \n",
      "\n",
      "\n",
      "18: ../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_creation.py \n",
      "\n",
      "from langchain import LLMChain, PromptTemplate\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "\n",
      "\n",
      "class TaskCreationChain(LLMChain):\n",
      "    \"\"\"Chain to generates tasks.\"\"\" \n",
      "\n",
      "\n",
      "19: ../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_prioritization.py \n",
      "\n",
      "class TaskPrioritizationChain(LLMChain):\n",
      "    \"\"\"Chain to prioritize tasks.\"\"\"\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm(cls, llm: BaseLanguageModel, verbose: bool = True) -> LLMChain:\n",
      "        \"\"\"Get the response parser.\"\"\"\n",
      "        task_prioritization_template = (\n",
      "            \"You are a task prioritization AI tasked with cleaning the formatting of \"\n",
      "            \"and reprioritizing the following tasks: {task_names}.\"\n",
      "            \" Consider the ultimate objective of your team: {objective}.\"\n",
      "            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n",
      "            \" #. First task\"\n",
      "            \" #. Second task\"\n",
      "            \" Start the task list with number {next_task_id}.\"\n",
      "        )\n",
      "        prompt = PromptTemplate(\n",
      "            template=task_prioritization_template,\n",
      "            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n",
      "        )\n",
      "        return cls(prompt=prompt, llm=llm, verbose=verbose) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ask_question(qa, question):\n",
    "    result = qa({\"query\": question})\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['result']} \\n\")\n",
    "    print(f\"**Sources**: {result['source_documents']} \\n\")\n",
    "    for i, s in enumerate(result['source_documents']):\n",
    "        print(f\"{i}: {s.metadata['source']} \\n\")\n",
    "        print(f\"{s.page_content} \\n\")\n",
    "        print()\n",
    "\n",
    "ask_question(qa2, \"What is the langchain class hierarchy?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> **Question**: What is the langchain class hierarchy? \n",
    "\n",
    "**Answer**: The LangChain class hierarchy includes various classes and components used to create, manage, and interact with language models, chains, prompts, tools, and other utilities. Here is an overview of the class hierarchy:\n",
    "\n",
    "- Chain (Base class for all chains)\n",
    "  - LLMChain (Language model chain)\n",
    "    - TaskCreationChain\n",
    "    - TaskPrioritizationChain\n",
    "  - LLMBashChain (Language model bash chain)\n",
    "  - LLMCheckerChain (Language model checker chain)\n",
    "  - LLMMathChain (Language model math chain)\n",
    "  - PALChain (PAL chain)\n",
    "  - QAWithSourcesChain (Question answering with sources chain)\n",
    "    - VectorDBQAWithSourcesChain\n",
    "  - VectorDBQA (Retrieval QA chain)\n",
    "  - SQLDatabaseChain (SQL database chain)\n",
    "  - APIChain (API chain)\n",
    "    - OpenAPIEndpointChain\n",
    "  - AnalyzeDocumentChain (Analyze document chain)\n",
    "  - ConstitutionalChain (Constitutional chain)\n",
    "  - ConversationChain (Conversation chain)\n",
    "  - RouterChain (Router chain)\n",
    "    - LLMRouterChain\n",
    "    - MultiRouteChain\n",
    "    - MultiPromptChain\n",
    "    - MultiRetrievalQAChain\n",
    "  - GraphQAChain (Graph QA chain)\n",
    "    - GraphCypherQAChain\n",
    "  - HypotheticalDocumentEmbedder (Hyde chain)\n",
    "  - SequentialChain (Sequential chain)\n",
    "\n",
    "- BaseLanguageModel (Base class for language models)\n",
    "  - AI21\n",
    "  - AlephAlpha\n",
    "  - Anthropic\n",
    "  - Anyscale\n",
    "  - Banana\n",
    "  - Beam\n",
    "  - Bedrock\n",
    "  - CerebriumAI\n",
    "  - Cohere\n",
    "  - CTransformers\n",
    "  - Databricks\n",
    "  - DeepInfra\n",
    "  - FakeListLLM\n",
    "  - ForefrontAI\n",
    "  - GooglePalm\n",
    "  - GooseAI\n",
    "  - GPT4All\n",
    "  - HuggingFaceEndpoint\n",
    "  - HuggingFaceHub\n",
    "  - HuggingFacePipeline\n",
    "  - HuggingFaceTextGenInference\n",
    "  - HumanInputLLM\n",
    "  - LlamaCpp\n",
    "  - Modal\n",
    "  - MosaicML\n",
    "  - NLPCloud\n",
    "  - OpenAI\n",
    "  - OpenAIChat\n",
    "  - OpenLM\n",
    "  - Petals\n",
    "  - PipelineAI\n",
    "  - PredictionGuard\n",
    "  - PromptLayerOpenAI\n",
    "  - PromptLayerOpenAIChat\n",
    "  - Replicate\n",
    "  - RWKV\n",
    "  - SagemakerEndpoint\n",
    "  - SelfHostedPipeline\n",
    "  - SelfHostedHuggingFaceLLM\n",
    "  - StochasticAI\n",
    "  - VertexAI\n",
    "  - Writer\n",
    "\n",
    "- BasePromptTemplate (Base class for prompt templates)\n",
    "  - PromptTemplate\n",
    "  - FewShotPromptTemplate\n",
    "\n",
    "This hierarchy outlines the main classes used to build and manage various chains, language models, and prompts within the LangChain library. Note that there are many other classes and utility functions that are not included in this hierarchy, as they support these main classes in specific tasks and functionalities. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat(qa, question):\n",
    "    result = qa({\"query\": question})\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['result']} \\n\")\n",
    "    print(f\"**Sources**: {result['source_documents']} \\n\")\n",
    "    for i, s in enumerate(result['source_documents']):\n",
    "        print(f\"{i}: {s.metadata['source']} \\n\")\n",
    "        print(f\"{s.page_content} \\n\")\n",
    "        print()\n",
    "\n",
    "ask_question(qa2, \"What is the langchain class hierarchy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qa\u001b[39m.\u001b[39;49mget_chat_history()\n\u001b[1;32m      2\u001b[0m qa\u001b[39m.\u001b[39minput_keys\n\u001b[1;32m      3\u001b[0m qa\u001b[39m.\u001b[39moutput_keys\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "qa.get_chat_history\n",
    "qa.input_keys\n",
    "qa.output_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is the langchain class hierarchy?',\n",
       "  \"The LangChain class hierarchy consists of various classes and modules, organized mainly into Agents, Chains, LLMs (Language Models), Prompts, Tools, and Utilities. Here's an overview of the main classes in each category:\\n\\n1. Agents:\\n   - MRKLChain\\n   - ReActChain\\n   - SelfAskWithSearchChain\\n\\n2. Chains:\\n   - Base Chains:\\n     - Chain\\n     - APIChain\\n     - LLMChain\\n     - LLMBashChain\\n     - LLMCheckerChain\\n     - LLMMathChain\\n     - PALChain\\n     - QAWithSourcesChain\\n     - SQLDatabaseChain\\n     - VectorDBQA\\n     - VectorDBQAWithSourcesChain\\n   - Conversational Chains:\\n     - ConversationChain\\n     - TaskCreationChain\\n     - TaskPrioritizationChain\\n   - Specialized Chains:\\n     - ConstitutionalChain\\n     - ChatVectorDBChain\\n     - ConversationalRetrievalChain\\n     - RouterChain\\n     - MultiRouteChain\\n     - MultiPromptChain\\n     - MultiRetrievalQAChain\\n     - LLMRouterChain\\n\\n3. LLMs (Language Models):\\n   - AI21\\n   - AlephAlpha\\n   - Anthropic\\n   - Anyscale\\n   - Banana\\n   - Beam\\n   - Bedrock\\n   - CerebriumAI\\n   - Cohere\\n   - CTransformers\\n   - Databricks\\n   - DeepInfra\\n   - FakeListLLM\\n   - ForefrontAI\\n   - GooglePalm\\n   - GooseAI\\n   - GPT4All\\n   - HuggingFaceEndpoint\\n   - HuggingFaceHub\\n   - HuggingFacePipeline\\n   - HuggingFaceTextGenInference\\n   - HumanInputLLM\\n   - LlamaCpp\\n   - Modal\\n   - MosaicML\\n   - NLPCloud\\n   - OpenAI\\n   - OpenAIChat\\n   - OpenLM\\n   - Petals\\n   - PipelineAI\\n   - Replicate\\n   - RWKV\\n   - SagemakerEndpoint\\n   - StochasticAI\\n   - VertexAI\\n   - Writer\\n\\n4. Prompts:\\n   - BasePromptTemplate\\n   - FewShotPromptTemplate\\n   - Prompt\\n   - PromptTemplate\\n\\n5. Tools:\\n   - ArxivQueryRun\\n   - BingSearchRun\\n   - DuckDuckGoSearchRun\\n   - GoogleSearchResults\\n   - GoogleSearchRun\\n   - GoogleSerperResults\\n   - GoogleSerperRun\\n   - HumanInputRun\\n   - MetaphorSearchResults\\n   - SearxSearchResults\\n   - SearxSearchRun\\n   - WikipediaQueryRun\\n   - WolframAlphaQueryRun\\n   - OpenWeatherMapQueryRun\\n\\n6. Utilities:\\n   - ArxivAPIWrapper\\n   - BingSearchAPIWrapper\\n   - DuckDuckGoSearchAPIWrapper\\n   - GoogleSearchAPIWrapper\\n   - GoogleSerperAPIWrapper\\n   - MetaphorSearchAPIWrapper\\n   - LambdaWrapper\\n   - GraphQLAPIWrapper\\n   - SearxSearchWrapper\\n   - SerpAPIWrapper\\n   - TwilioAPIWrapper\\n   - WikipediaAPIWrapper\\n   - WolframAlphaAPIWrapper\\n   - OpenWeatherMapAPIWrapper\\n\\nPlease note that this list is not exhaustive and only includes the main classes for each category. There might be other classes and subclasses within the LangChain library.\")]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('What is the langchain class hierarchy?',\n",
       "  \"The LangChain class hierarchy consists of various classes and modules, organized mainly into Agents, Chains, LLMs (Language Models), Prompts, Tools, and Utilities. Here's an overview of the main classes in each category:\\n\\n1. Agents:\\n   - MRKLChain\\n   - ReActChain\\n   - SelfAskWithSearchChain\\n\\n2. Chains:\\n   - Base Chains:\\n     - Chain\\n     - APIChain\\n     - LLMChain\\n     - LLMBashChain\\n     - LLMCheckerChain\\n     - LLMMathChain\\n     - PALChain\\n     - QAWithSourcesChain\\n     - SQLDatabaseChain\\n     - VectorDBQA\\n     - VectorDBQAWithSourcesChain\\n   - Conversational Chains:\\n     - ConversationChain\\n     - TaskCreationChain\\n     - TaskPrioritizationChain\\n   - Specialized Chains:\\n     - ConstitutionalChain\\n     - ChatVectorDBChain\\n     - ConversationalRetrievalChain\\n     - RouterChain\\n     - MultiRouteChain\\n     - MultiPromptChain\\n     - MultiRetrievalQAChain\\n     - LLMRouterChain\\n\\n3. LLMs (Language Models):\\n   - AI21\\n   - AlephAlpha\\n   - Anthropic\\n   - Anyscale\\n   - Banana\\n   - Beam\\n   - Bedrock\\n   - CerebriumAI\\n   - Cohere\\n   - CTransformers\\n   - Databricks\\n   - DeepInfra\\n   - FakeListLLM\\n   - ForefrontAI\\n   - GooglePalm\\n   - GooseAI\\n   - GPT4All\\n   - HuggingFaceEndpoint\\n   - HuggingFaceHub\\n   - HuggingFacePipeline\\n   - HuggingFaceTextGenInference\\n   - HumanInputLLM\\n   - LlamaCpp\\n   - Modal\\n   - MosaicML\\n   - NLPCloud\\n   - OpenAI\\n   - OpenAIChat\\n   - OpenLM\\n   - Petals\\n   - PipelineAI\\n   - Replicate\\n   - RWKV\\n   - SagemakerEndpoint\\n   - StochasticAI\\n   - VertexAI\\n   - Writer\\n\\n4. Prompts:\\n   - BasePromptTemplate\\n   - FewShotPromptTemplate\\n   - Prompt\\n   - PromptTemplate\\n\\n5. Tools:\\n   - ArxivQueryRun\\n   - BingSearchRun\\n   - DuckDuckGoSearchRun\\n   - GoogleSearchResults\\n   - GoogleSearchRun\\n   - GoogleSerperResults\\n   - GoogleSerperRun\\n   - HumanInputRun\\n   - MetaphorSearchResults\\n   - SearxSearchResults\\n   - SearxSearchRun\\n   - WikipediaQueryRun\\n   - WolframAlphaQueryRun\\n   - OpenWeatherMapQueryRun\\n\\n6. Utilities:\\n   - ArxivAPIWrapper\\n   - BingSearchAPIWrapper\\n   - DuckDuckGoSearchAPIWrapper\\n   - GoogleSearchAPIWrapper\\n   - GoogleSerperAPIWrapper\\n   - MetaphorSearchAPIWrapper\\n   - LambdaWrapper\\n   - GraphQLAPIWrapper\\n   - SearxSearchWrapper\\n   - SerpAPIWrapper\\n   - TwilioAPIWrapper\\n   - WikipediaAPIWrapper\\n   - WolframAlphaAPIWrapper\\n   - OpenWeatherMapAPIWrapper\\n\\nPlease note that this list is not exhaustive and only includes the main classes for each category. There might be other classes and subclasses within the LangChain library.\")]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"chat_history\"]\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the users question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "from langchain.agents import MRKLChain, ReActChain, SelfAskWithSearchChain\n",
      "from langchain.cache import BaseCache\n",
      "from langchain.chains import (\n",
      "    ConversationChain,\n",
      "    LLMBashChain,\n",
      "    LLMChain,\n",
      "    LLMCheckerChain,\n",
      "    LLMMathChain,\n",
      "    PALChain,\n",
      "    QAWithSourcesChain,\n",
      "    SQLDatabaseChain,\n",
      "    VectorDBQA,\n",
      "    VectorDBQAWithSourcesChain,\n",
      ")\n",
      "from langchain.docstore import InMemoryDocstore, Wikipedia\n",
      "from langchain.llms import (\n",
      "    Anthropic,\n",
      "    Banana,\n",
      "    CerebriumAI,\n",
      "    Cohere,\n",
      "    ForefrontAI,\n",
      "    GooseAI,\n",
      "    HuggingFaceHub,\n",
      "    HuggingFaceTextGenInference,\n",
      "    LlamaCpp,\n",
      "    Modal,\n",
      "    OpenAI,\n",
      "    Petals,\n",
      "    PipelineAI,\n",
      "    SagemakerEndpoint,\n",
      "    StochasticAI,\n",
      "    Writer,\n",
      ")\n",
      "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
      "from langchain.prompts import (\n",
      "    BasePromptTemplate,\n",
      "    FewShotPromptTemplate,\n",
      "    Prompt,\n",
      "    PromptTemplate,\n",
      ")\n",
      "from langchain.sql_database import SQLDatabase\n",
      "from langchain.utilities.arxiv import ArxivAPIWrapper\n",
      "from langchain.utilities.google_search import GoogleSearchAPIWrapper\n",
      "from langchain.utilities.google_serper import GoogleSerperAPIWrapper\n",
      "from langchain.utilities.powerbi import PowerBIDataset\n",
      "from langchain.utilities.searx_search import SearxSearchWrapper\n",
      "from langchain.utilities.serpapi import SerpAPIWrapper\n",
      "from langchain.utilities.wikipedia import WikipediaAPIWrapper\n",
      "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
      "from langchain.vectorstores import FAISS, ElasticVectorSearch\n",
      "\n",
      "from langchain.chains.api.base import APIChain\n",
      "from langchain.chains.base import Chain\n",
      "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\n",
      "from langchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain\n",
      "from langchain.chains.combine_documents.refine import RefineDocumentsChain\n",
      "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
      "from langchain.chains.hyde.base import HypotheticalDocumentEmbedder\n",
      "from langchain.chains.llm import LLMChain\n",
      "from langchain.chains.llm_bash.base import LLMBashChain\n",
      "from langchain.chains.llm_checker.base import LLMCheckerChain\n",
      "from langchain.chains.llm_math.base import LLMMathChain\n",
      "from langchain.chains.llm_requests import LLMRequestsChain\n",
      "from langchain.chains.pal.base import PALChain\n",
      "from langchain.chains.qa_with_sources.base import QAWithSourcesChain\n",
      "from langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain\n",
      "from langchain.chains.retrieval_qa.base import VectorDBQA\n",
      "from langchain.chains.sql_database.base import SQLDatabaseChain\n",
      "from langchain.llms.loading import load_llm, load_llm_from_config\n",
      "from langchain.prompts.loading import load_prompt, load_prompt_from_config\n",
      "from langchain.utilities.loading import try_load_from_hub\n",
      "\n",
      "\"\"\"Chains are easily reusable components which can be linked together.\"\"\"\n",
      "from langchain.chains.api.base import APIChain\n",
      "from langchain.chains.api.openapi.chain import OpenAPIEndpointChain\n",
      "from langchain.chains.combine_documents.base import AnalyzeDocumentChain\n",
      "from langchain.chains.constitutional_ai.base import ConstitutionalChain\n",
      "from langchain.chains.conversation.base import ConversationChain\n",
      "from langchain.chains.conversational_retrieval.base import (\n",
      "    ChatVectorDBChain,\n",
      "    ConversationalRetrievalChain,\n",
      ")\n",
      "from langchain.chains.flare.base import FlareChain\n",
      "from langchain.chains.graph_qa.base import GraphQAChain\n",
      "from langchain.chains.graph_qa.cypher import GraphCypherQAChain\n",
      "from langchain.chains.hyde.base import HypotheticalDocumentEmbedder\n",
      "from langchain.chains.llm import LLMChain\n",
      "from langchain.chains.llm_bash.base import LLMBashChain\n",
      "from langchain.chains.llm_checker.base import LLMCheckerChain\n",
      "from langchain.chains.llm_math.base import LLMMathChain\n",
      "from langchain.chains.llm_requests import LLMRequestsChain\n",
      "from langchain.chains.llm_summarization_checker.base import LLMSummarizationCheckerChain\n",
      "from langchain.chains.loading import load_chain\n",
      "from langchain.chains.mapreduce import MapReduceChain\n",
      "from langchain.chains.moderation import OpenAIModerationChain\n",
      "from langchain.chains.pal.base import PALChain\n",
      "from langchain.chains.qa_generation.base import QAGenerationChain\n",
      "from langchain.chains.qa_with_sources.base import QAWithSourcesChain\n",
      "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
      "from langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain\n",
      "from langchain.chains.retrieval_qa.base import RetrievalQA, VectorDBQA\n",
      "from langchain.chains.sequential import SequentialChain, SimpleSequentialChain\n",
      "from langchain.chains.sql_database.base import (\n",
      "    SQLDatabaseChain,\n",
      "    SQLDatabaseSequentialChain,\n",
      ")\n",
      "from langchain.chains.transform import TransformChain\n",
      "\n",
      "import langchain\n",
      "from langchain.callbacks.base import (\n",
      "    BaseCallbackHandler,\n",
      "    BaseCallbackManager,\n",
      "    ChainManagerMixin,\n",
      "    LLMManagerMixin,\n",
      "    RunManagerMixin,\n",
      "    ToolManagerMixin,\n",
      ")\n",
      "from langchain.callbacks.openai_info import OpenAICallbackHandler\n",
      "from langchain.callbacks.stdout import StdOutCallbackHandler\n",
      "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
      "from langchain.callbacks.tracers.langchain_v1 import LangChainTracerV1, TracerSessionV1\n",
      "from langchain.callbacks.tracers.schemas import TracerSession\n",
      "from langchain.callbacks.tracers.stdout import ConsoleCallbackHandler\n",
      "from langchain.callbacks.tracers.wandb import WandbTracer\n",
      "from langchain.schema import (\n",
      "    AgentAction,\n",
      "    AgentFinish,\n",
      "    BaseMessage,\n",
      "    LLMResult,\n",
      "    get_buffer_string,\n",
      ")\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "Callbacks = Optional[Union[List[BaseCallbackHandler], BaseCallbackManager]]\n",
      "\n",
      "\"\"\"Base interface that all chains should implement.\"\"\"\n",
      "import inspect\n",
      "import json\n",
      "import warnings\n",
      "from abc import ABC, abstractmethod\n",
      "from pathlib import Path\n",
      "from typing import Any, Dict, List, Optional, Union\n",
      "\n",
      "import yaml\n",
      "from pydantic import BaseModel, Field, root_validator, validator\n",
      "\n",
      "import langchain\n",
      "from langchain.callbacks.base import BaseCallbackManager\n",
      "from langchain.callbacks.manager import (\n",
      "    AsyncCallbackManager,\n",
      "    AsyncCallbackManagerForChainRun,\n",
      "    CallbackManager,\n",
      "    CallbackManagerForChainRun,\n",
      "    Callbacks,\n",
      ")\n",
      "from langchain.schema import BaseMemory\n",
      "\n",
      "\n",
      "def _get_verbosity() -> bool:\n",
      "    return langchain.verbose\n",
      "\n",
      "\n",
      "class Chain(BaseModel, ABC):\n",
      "    \"\"\"Base interface that all chains should implement.\"\"\"\n",
      "\n",
      "from langchain import LLMChain, PromptTemplate\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "\n",
      "\n",
      "class TaskPrioritizationChain(LLMChain):\n",
      "    \"\"\"Chain to prioritize tasks.\"\"\"\n",
      "\n",
      "from langchain.llms.ai21 import AI21\n",
      "from langchain.llms.aleph_alpha import AlephAlpha\n",
      "from langchain.llms.anthropic import Anthropic\n",
      "from langchain.llms.anyscale import Anyscale\n",
      "from langchain.llms.bananadev import Banana\n",
      "from langchain.llms.base import BaseLLM\n",
      "from langchain.llms.beam import Beam\n",
      "from langchain.llms.bedrock import Bedrock\n",
      "from langchain.llms.cerebriumai import CerebriumAI\n",
      "from langchain.llms.cohere import Cohere\n",
      "from langchain.llms.ctransformers import CTransformers\n",
      "from langchain.llms.databricks import Databricks\n",
      "from langchain.llms.deepinfra import DeepInfra\n",
      "from langchain.llms.fake import FakeListLLM\n",
      "from langchain.llms.forefrontai import ForefrontAI\n",
      "from langchain.llms.google_palm import GooglePalm\n",
      "from langchain.llms.gooseai import GooseAI\n",
      "from langchain.llms.gpt4all import GPT4All\n",
      "from langchain.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
      "from langchain.llms.huggingface_hub import HuggingFaceHub\n",
      "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
      "from langchain.llms.huggingface_text_gen_inference import HuggingFaceTextGenInference\n",
      "from langchain.llms.human import HumanInputLLM\n",
      "from langchain.llms.llamacpp import LlamaCpp\n",
      "from langchain.llms.modal import Modal\n",
      "from langchain.llms.mosaicml import MosaicML\n",
      "from langchain.llms.nlpcloud import NLPCloud\n",
      "from langchain.llms.openai import AzureOpenAI, OpenAI, OpenAIChat\n",
      "from langchain.llms.openlm import OpenLM\n",
      "from langchain.llms.petals import Petals\n",
      "from langchain.llms.pipelineai import PipelineAI\n",
      "from langchain.llms.predictionguard import PredictionGuard\n",
      "from langchain.llms.promptlayer_openai import PromptLayerOpenAI, PromptLayerOpenAIChat\n",
      "from langchain.llms.replicate import Replicate\n",
      "from langchain.llms.rwkv import RWKV\n",
      "from langchain.llms.sagemaker_endpoint import SagemakerEndpoint\n",
      "from langchain.llms.self_hosted import SelfHostedPipeline\n",
      "from langchain.llms.self_hosted_hugging_face import SelfHostedHuggingFaceLLM\n",
      "from langchain.llms.stochasticai import StochasticAI\n",
      "from langchain.llms.vertexai import VertexAI\n",
      "from langchain.llms.writer import Writer\n",
      "\n",
      "\"\"\"Tests for correct functioning of chains.\"\"\"\n",
      "\n",
      "from langchain.chains.router.base import MultiRouteChain, RouterChain\n",
      "from langchain.chains.router.llm_router import LLMRouterChain\n",
      "from langchain.chains.router.multi_prompt import MultiPromptChain\n",
      "from langchain.chains.router.multi_retrieval_qa import MultiRetrievalQAChain\n",
      "\n",
      "__all__ = [\n",
      "    \"RouterChain\",\n",
      "    \"MultiRouteChain\",\n",
      "    \"MultiPromptChain\",\n",
      "    \"MultiRetrievalQAChain\",\n",
      "    \"LLMRouterChain\",\n",
      "]\n",
      "\n",
      "@property\n",
      "    def _chain_type(self) -> str:\n",
      "        return \"llm_bash_chain\"\n",
      "\n",
      "\"\"\"Chain for applying constitutional principles to the outputs of another chain.\"\"\"\n",
      "from typing import Any, Dict, List, Optional\n",
      "\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
      "from langchain.chains.base import Chain\n",
      "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
      "from langchain.chains.constitutional_ai.principles import PRINCIPLES\n",
      "from langchain.chains.constitutional_ai.prompts import CRITIQUE_PROMPT, REVISION_PROMPT\n",
      "from langchain.chains.llm import LLMChain\n",
      "from langchain.prompts.base import BasePromptTemplate\n",
      "\n",
      "\n",
      "class ConstitutionalChain(Chain):\n",
      "    \"\"\"Chain for applying constitutional principles.\n",
      "\n",
      "    Example:\n",
      "        .. code-block:: python\n",
      "\n",
      "            from langchain.llms import OpenAI\n",
      "            from langchain.chains import LLMChain, ConstitutionalChain\n",
      "            from langchain.chains.constitutional_ai.models \\\n",
      "                import ConstitutionalPrinciple\n",
      "\n",
      "\"\"\"LangChain+ Client.\"\"\"\n",
      "\n",
      "\n",
      "from langchain.client.langchain import LangChainPlusClient\n",
      "\n",
      "__all__ = [\"LangChainPlusClient\"]\n",
      "\n",
      "@property\n",
      "    def _chain_type(self) -> str:\n",
      "        return \"llm_bash_chain\"\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm(\n",
      "        cls,\n",
      "        llm: BaseLanguageModel,\n",
      "        prompt: BasePromptTemplate = PROMPT,\n",
      "        **kwargs: Any,\n",
      "    ) -> LLMBashChain:\n",
      "        llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "        return cls(llm_chain=llm_chain, **kwargs)\n",
      "\n",
      "@property\n",
      "    def _chain_type(self) -> str:\n",
      "        return \"llm_chain\"\n",
      "\n",
      "    @classmethod\n",
      "    def from_string(cls, llm: BaseLanguageModel, template: str) -> Chain:\n",
      "        \"\"\"Create LLMChain from LLM and template.\"\"\"\n",
      "        prompt_template = PromptTemplate.from_template(template)\n",
      "        return cls(llm=llm, prompt=prompt_template)\n",
      "\n",
      "\"\"\"Callback handlers that allow listening to events in LangChain.\"\"\"\n",
      "\n",
      "from langchain.callbacks.aim_callback import AimCallbackHandler\n",
      "from langchain.callbacks.clearml_callback import ClearMLCallbackHandler\n",
      "from langchain.callbacks.comet_ml_callback import CometCallbackHandler\n",
      "from langchain.callbacks.manager import (\n",
      "    get_openai_callback,\n",
      "    tracing_enabled,\n",
      "    wandb_tracing_enabled,\n",
      ")\n",
      "from langchain.callbacks.mlflow_callback import MlflowCallbackHandler\n",
      "from langchain.callbacks.openai_info import OpenAICallbackHandler\n",
      "from langchain.callbacks.stdout import StdOutCallbackHandler\n",
      "from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler\n",
      "from langchain.callbacks.wandb_callback import WandbCallbackHandler\n",
      "from langchain.callbacks.whylabs_callback import WhyLabsCallbackHandler\n",
      "\n",
      "from langchain.agents.tools import Tool\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "from langchain.callbacks.base import BaseCallbackManager\n",
      "from langchain.callbacks.manager import Callbacks\n",
      "from langchain.chains.api import news_docs, open_meteo_docs, podcast_docs, tmdb_docs\n",
      "from langchain.chains.api.base import APIChain\n",
      "from langchain.chains.llm_math.base import LLMMathChain\n",
      "from langchain.chains.pal.base import PALChain\n",
      "from langchain.requests import TextRequestsWrapper\n",
      "from langchain.tools.arxiv.tool import ArxivQueryRun\n",
      "from langchain.tools.base import BaseTool\n",
      "from langchain.tools.bing_search.tool import BingSearchRun\n",
      "from langchain.tools.ddg_search.tool import DuckDuckGoSearchRun\n",
      "from langchain.tools.google_search.tool import GoogleSearchResults, GoogleSearchRun\n",
      "from langchain.tools.metaphor_search.tool import MetaphorSearchResults\n",
      "from langchain.tools.google_serper.tool import GoogleSerperResults, GoogleSerperRun\n",
      "from langchain.tools.graphql.tool import BaseGraphQLTool\n",
      "from langchain.tools.human.tool import HumanInputRun\n",
      "from langchain.tools.python.tool import PythonREPLTool\n",
      "from langchain.tools.requests.tool import (\n",
      "    RequestsDeleteTool,\n",
      "    RequestsGetTool,\n",
      "    RequestsPatchTool,\n",
      "    RequestsPostTool,\n",
      "    RequestsPutTool,\n",
      ")\n",
      "from langchain.tools.scenexplain.tool import SceneXplainTool\n",
      "from langchain.tools.searx_search.tool import SearxSearchResults, SearxSearchRun\n",
      "from langchain.tools.shell.tool import ShellTool\n",
      "from langchain.tools.wikipedia.tool import WikipediaQueryRun\n",
      "from langchain.tools.wolfram_alpha.tool import WolframAlphaQueryRun\n",
      "from langchain.tools.openweathermap.tool import OpenWeatherMapQueryRun\n",
      "from langchain.utilities import ArxivAPIWrapper\n",
      "from langchain.utilities.bing_search import BingSearchAPIWrapper\n",
      "from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
      "from langchain.utilities.google_search import GoogleSearchAPIWrapper\n",
      "from langchain.utilities.google_serper import GoogleSerperAPIWrapper\n",
      "from langchain.utilities.metaphor_search import MetaphorSearchAPIWrapper\n",
      "from langchain.utilities.awslambda import LambdaWrapper\n",
      "from langchain.utilities.graphql import GraphQLAPIWrapper\n",
      "from langchain.utilities.searx_search import SearxSearchWrapper\n",
      "from langchain.utilities.serpapi import SerpAPIWrapper\n",
      "from langchain.utilities.twilio import TwilioAPIWrapper\n",
      "from langchain.utilities.wikipedia import WikipediaAPIWrapper\n",
      "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
      "from langchain.utilities.openweathermap import OpenWeatherMapAPIWrapper\n",
      "\n",
      "@property\n",
      "    def _chain_type(self) -> str:\n",
      "        return \"llm_checker_chain\"\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm(\n",
      "        cls,\n",
      "        llm: BaseLanguageModel,\n",
      "        create_draft_answer_prompt: PromptTemplate = CREATE_DRAFT_ANSWER_PROMPT,\n",
      "        list_assertions_prompt: PromptTemplate = LIST_ASSERTIONS_PROMPT,\n",
      "        check_assertions_prompt: PromptTemplate = CHECK_ASSERTIONS_PROMPT,\n",
      "        revised_answer_prompt: PromptTemplate = REVISED_ANSWER_PROMPT,\n",
      "        **kwargs: Any,\n",
      "    ) -> LLMCheckerChain:\n",
      "        question_to_checked_assertions_chain = (\n",
      "            _load_question_to_checked_assertions_chain(\n",
      "                llm,\n",
      "                create_draft_answer_prompt,\n",
      "                list_assertions_prompt,\n",
      "                check_assertions_prompt,\n",
      "                revised_answer_prompt,\n",
      "            )\n",
      "        )\n",
      "        return cls(\n",
      "            question_to_checked_assertions_chain=question_to_checked_assertions_chain,\n",
      "            **kwargs,\n",
      "        )\n",
      "\n",
      "\"\"\"Chain for chatting with a vector database.\"\"\"\n",
      "from __future__ import annotations\n",
      "\n",
      "import warnings\n",
      "from abc import abstractmethod\n",
      "from pathlib import Path\n",
      "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
      "\n",
      "from pydantic import Extra, Field, root_validator\n",
      "\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "from langchain.callbacks.manager import (\n",
      "    AsyncCallbackManagerForChainRun,\n",
      "    CallbackManagerForChainRun,\n",
      ")\n",
      "from langchain.chains.base import Chain\n",
      "from langchain.chains.combine_documents.base import BaseCombineDocumentsChain\n",
      "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
      "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
      "from langchain.chains.llm import LLMChain\n",
      "from langchain.chains.question_answering import load_qa_chain\n",
      "from langchain.prompts.base import BasePromptTemplate\n",
      "from langchain.schema import BaseMessage, BaseRetriever, Document\n",
      "from langchain.vectorstores.base import VectorStore\n",
      "\n",
      "from langchain import LLMChain, PromptTemplate\n",
      "from langchain.base_language import BaseLanguageModel\n",
      "\n",
      "\n",
      "class TaskCreationChain(LLMChain):\n",
      "    \"\"\"Chain to generates tasks.\"\"\"\n",
      "\n",
      "class TaskPrioritizationChain(LLMChain):\n",
      "    \"\"\"Chain to prioritize tasks.\"\"\"\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm(cls, llm: BaseLanguageModel, verbose: bool = True) -> LLMChain:\n",
      "        \"\"\"Get the response parser.\"\"\"\n",
      "        task_prioritization_template = (\n",
      "            \"You are a task prioritization AI tasked with cleaning the formatting of \"\n",
      "            \"and reprioritizing the following tasks: {task_names}.\"\n",
      "            \" Consider the ultimate objective of your team: {objective}.\"\n",
      "            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n",
      "            \" #. First task\"\n",
      "            \" #. Second task\"\n",
      "            \" Start the task list with number {next_task_id}.\"\n",
      "        )\n",
      "        prompt = PromptTemplate(\n",
      "            template=task_prioritization_template,\n",
      "            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n",
      "        )\n",
      "        return cls(prompt=prompt, llm=llm, verbose=verbose)\n",
      "Human: What is the langchain class hierarchy?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "-> **Question**: What is the langchain class hierarchy? \n",
      "\n",
      "**Answer**: The LangChain class hierarchy consists of various classes and modules, organized mainly into Agents, Chains, LLMs (Language Models), Prompts, Tools, and Utilities. Here's an overview of the main classes in each category:\n",
      "\n",
      "1. Agents:\n",
      "   - MRKLChain\n",
      "   - ReActChain\n",
      "   - SelfAskWithSearchChain\n",
      "\n",
      "2. Chains:\n",
      "   - Base Chains:\n",
      "     - Chain\n",
      "     - APIChain\n",
      "     - LLMChain\n",
      "     - LLMBashChain\n",
      "     - LLMCheckerChain\n",
      "     - LLMMathChain\n",
      "     - PALChain\n",
      "     - QAWithSourcesChain\n",
      "     - SQLDatabaseChain\n",
      "     - VectorDBQA\n",
      "     - VectorDBQAWithSourcesChain\n",
      "   - Conversational Chains:\n",
      "     - ConversationChain\n",
      "     - TaskCreationChain\n",
      "     - TaskPrioritizationChain\n",
      "   - Specialized Chains:\n",
      "     - ConstitutionalChain\n",
      "     - ChatVectorDBChain\n",
      "     - ConversationalRetrievalChain\n",
      "     - RouterChain\n",
      "     - MultiRouteChain\n",
      "     - MultiPromptChain\n",
      "     - MultiRetrievalQAChain\n",
      "     - LLMRouterChain\n",
      "\n",
      "3. LLMs (Language Models):\n",
      "   - AI21\n",
      "   - AlephAlpha\n",
      "   - Anthropic\n",
      "   - Anyscale\n",
      "   - Banana\n",
      "   - Beam\n",
      "   - Bedrock\n",
      "   - CerebriumAI\n",
      "   - Cohere\n",
      "   - CTransformers\n",
      "   - Databricks\n",
      "   - DeepInfra\n",
      "   - FakeListLLM\n",
      "   - ForefrontAI\n",
      "   - GooglePalm\n",
      "   - GooseAI\n",
      "   - GPT4All\n",
      "   - HuggingFaceEndpoint\n",
      "   - HuggingFaceHub\n",
      "   - HuggingFacePipeline\n",
      "   - HuggingFaceTextGenInference\n",
      "   - HumanInputLLM\n",
      "   - LlamaCpp\n",
      "   - Modal\n",
      "   - MosaicML\n",
      "   - NLPCloud\n",
      "   - OpenAI\n",
      "   - OpenAIChat\n",
      "   - OpenLM\n",
      "   - Petals\n",
      "   - PipelineAI\n",
      "   - Replicate\n",
      "   - RWKV\n",
      "   - SagemakerEndpoint\n",
      "   - StochasticAI\n",
      "   - VertexAI\n",
      "   - Writer\n",
      "\n",
      "4. Prompts:\n",
      "   - BasePromptTemplate\n",
      "   - FewShotPromptTemplate\n",
      "   - Prompt\n",
      "   - PromptTemplate\n",
      "\n",
      "5. Tools:\n",
      "   - ArxivQueryRun\n",
      "   - BingSearchRun\n",
      "   - DuckDuckGoSearchRun\n",
      "   - GoogleSearchResults\n",
      "   - GoogleSearchRun\n",
      "   - GoogleSerperResults\n",
      "   - GoogleSerperRun\n",
      "   - HumanInputRun\n",
      "   - MetaphorSearchResults\n",
      "   - SearxSearchResults\n",
      "   - SearxSearchRun\n",
      "   - WikipediaQueryRun\n",
      "   - WolframAlphaQueryRun\n",
      "   - OpenWeatherMapQueryRun\n",
      "\n",
      "6. Utilities:\n",
      "   - ArxivAPIWrapper\n",
      "   - BingSearchAPIWrapper\n",
      "   - DuckDuckGoSearchAPIWrapper\n",
      "   - GoogleSearchAPIWrapper\n",
      "   - GoogleSerperAPIWrapper\n",
      "   - MetaphorSearchAPIWrapper\n",
      "   - LambdaWrapper\n",
      "   - GraphQLAPIWrapper\n",
      "   - SearxSearchWrapper\n",
      "   - SerpAPIWrapper\n",
      "   - TwilioAPIWrapper\n",
      "   - WikipediaAPIWrapper\n",
      "   - WolframAlphaAPIWrapper\n",
      "   - OpenWeatherMapAPIWrapper\n",
      "\n",
      "Please note that this list is not exhaustive and only includes the main classes for each category. There might be other classes and subclasses within the LangChain library. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is the langchain class hierarchy?\",\n",
    "    # \"What classes are derived from the Chain class?\",\n",
    "    # \"What classes and functions in the ./langchain/utilities/ folder are not covered by unit tests?\",\n",
    "    # \"What one improvement do you propose in code in relation to the class herarchy for the Chain class?\",\n",
    "] \n",
    "chat_history = []\n",
    "\n",
    "for question in questions:  \n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> **Question**: What is the langchain class hierarchy? \n",
    "\n",
    "**Answer**: The LangChain class hierarchy consists of various classes and modules, organized mainly into Agents, Chains, LLMs (Language Models), Prompts, Tools, and Utilities. Here's an overview of the main classes in each category:\n",
    "\n",
    "1. Agents:\n",
    "   - `MRKLChain`\n",
    "   - `ReActChain`\n",
    "   - `SelfAskWithSearchChain`\n",
    "\n",
    "2. Chains:\n",
    "   - Base Chains:\n",
    "     - `Chain`\n",
    "     - `APIChain`\n",
    "     - `LLMChain`\n",
    "     - `LLMBashChain`\n",
    "     - `LLMCheckerChain`\n",
    "     - `LLMMathChain`\n",
    "     - `PALChain`\n",
    "     - `QAWithSourcesChain`\n",
    "     - `SQLDatabaseChain`\n",
    "     - `VectorDBQA`\n",
    "     - `VectorDBQAWithSourcesChain`\n",
    "   - Conversational Chains:\n",
    "     - `ConversationChain`\n",
    "     - `TaskCreationChain`\n",
    "     - `TaskPrioritizationChain`\n",
    "   - Specialized Chains:\n",
    "     - `ConstitutionalChain`\n",
    "     - `ChatVectorDBChain`\n",
    "     - `ConversationalRetrievalChain`\n",
    "     - `RouterChain`\n",
    "     - `MultiRouteChain`\n",
    "     - `MultiPromptChain`\n",
    "     - `MultiRetrievalQAChain`\n",
    "     - `LLMRouterChain`\n",
    "\n",
    "3. LLMs (Language Models):\n",
    "   - AI21\n",
    "   - AlephAlpha\n",
    "   - Anthropic\n",
    "   - Anyscale\n",
    "   - Banana\n",
    "   - Beam\n",
    "   - Bedrock\n",
    "   - CerebriumAI\n",
    "   - Cohere\n",
    "   - CTransformers\n",
    "   - Databricks\n",
    "   - DeepInfra\n",
    "   - FakeListLLM\n",
    "   - ForefrontAI\n",
    "   - GooglePalm\n",
    "   - GooseAI\n",
    "   - GPT4All\n",
    "   - HuggingFaceEndpoint\n",
    "   - HuggingFaceHub\n",
    "   - HuggingFacePipeline\n",
    "   - HuggingFaceTextGenInference\n",
    "   - HumanInputLLM\n",
    "   - LlamaCpp\n",
    "   - Modal\n",
    "   - MosaicML\n",
    "   - NLPCloud\n",
    "   - OpenAI\n",
    "   - OpenAIChat\n",
    "   - OpenLM\n",
    "   - Petals\n",
    "   - PipelineAI\n",
    "   - Replicate\n",
    "   - RWKV\n",
    "   - SagemakerEndpoint\n",
    "   - StochasticAI\n",
    "   - VertexAI\n",
    "   - Writer\n",
    "\n",
    "4. Prompts:\n",
    "   - `BasePromptTemplate`\n",
    "   - `FewShotPromptTemplate`\n",
    "   - `Prompt`\n",
    "   - `PromptTemplate`\n",
    "\n",
    "5. Tools:\n",
    "   - `ArxivQueryRun`\n",
    "   - `BingSearchRun`\n",
    "   - `DuckDuckGoSearchRun`\n",
    "   - `GoogleSearchResults`\n",
    "   - `GoogleSearchRun`\n",
    "   - `GoogleSerperResults`\n",
    "   - `GoogleSerperRun`\n",
    "   - `HumanInputRun`\n",
    "   - `MetaphorSearchResults`\n",
    "   - `SearxSearchResults`\n",
    "   - `SearxSearchRun`\n",
    "   - `WikipediaQueryRun`\n",
    "   - `WolframAlphaQueryRun`\n",
    "   - `OpenWeatherMapQueryRun`\n",
    "\n",
    "6. Utilities:\n",
    "   - `ArxivAPIWrapper`\n",
    "   - `BingSearchAPIWrapper`\n",
    "   - `DuckDuckGoSearchAPIWrapper`\n",
    "   - `GoogleSearchAPIWrapper`\n",
    "   - `GoogleSerperAPIWrapper`\n",
    "   - `MetaphorSearchAPIWrapper`\n",
    "   - `LambdaWrapper`\n",
    "   - `GraphQLAPIWrapper`\n",
    "   - `SearxSearchWrapper`\n",
    "   - `SerpAPIWrapper`\n",
    "   - `TwilioAPIWrapper`\n",
    "   - `WikipediaAPIWrapper`\n",
    "   - `WolframAlphaAPIWrapper`\n",
    "   - `OpenWeatherMapAPIWrapper`\n",
    "\n",
    "Please note that this list is not exhaustive and only includes the main classes for each category. There might be other classes and subclasses within the LangChain library. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the langchain class hierarchy?',\n",
       " 'chat_history': [('What is the langchain class hierarchy?',\n",
       "   \"The LangChain class hierarchy consists of various classes and modules, organized mainly into Agents, Chains, LLMs (Language Models), Prompts, Tools, and Utilities. Here's an overview of the main classes in each category:\\n\\n1. Agents:\\n   - MRKLChain\\n   - ReActChain\\n   - SelfAskWithSearchChain\\n\\n2. Chains:\\n   - Base Chains:\\n     - Chain\\n     - APIChain\\n     - LLMChain\\n     - LLMBashChain\\n     - LLMCheckerChain\\n     - LLMMathChain\\n     - PALChain\\n     - QAWithSourcesChain\\n     - SQLDatabaseChain\\n     - VectorDBQA\\n     - VectorDBQAWithSourcesChain\\n   - Conversational Chains:\\n     - ConversationChain\\n     - TaskCreationChain\\n     - TaskPrioritizationChain\\n   - Specialized Chains:\\n     - ConstitutionalChain\\n     - ChatVectorDBChain\\n     - ConversationalRetrievalChain\\n     - RouterChain\\n     - MultiRouteChain\\n     - MultiPromptChain\\n     - MultiRetrievalQAChain\\n     - LLMRouterChain\\n\\n3. LLMs (Language Models):\\n   - AI21\\n   - AlephAlpha\\n   - Anthropic\\n   - Anyscale\\n   - Banana\\n   - Beam\\n   - Bedrock\\n   - CerebriumAI\\n   - Cohere\\n   - CTransformers\\n   - Databricks\\n   - DeepInfra\\n   - FakeListLLM\\n   - ForefrontAI\\n   - GooglePalm\\n   - GooseAI\\n   - GPT4All\\n   - HuggingFaceEndpoint\\n   - HuggingFaceHub\\n   - HuggingFacePipeline\\n   - HuggingFaceTextGenInference\\n   - HumanInputLLM\\n   - LlamaCpp\\n   - Modal\\n   - MosaicML\\n   - NLPCloud\\n   - OpenAI\\n   - OpenAIChat\\n   - OpenLM\\n   - Petals\\n   - PipelineAI\\n   - Replicate\\n   - RWKV\\n   - SagemakerEndpoint\\n   - StochasticAI\\n   - VertexAI\\n   - Writer\\n\\n4. Prompts:\\n   - BasePromptTemplate\\n   - FewShotPromptTemplate\\n   - Prompt\\n   - PromptTemplate\\n\\n5. Tools:\\n   - ArxivQueryRun\\n   - BingSearchRun\\n   - DuckDuckGoSearchRun\\n   - GoogleSearchResults\\n   - GoogleSearchRun\\n   - GoogleSerperResults\\n   - GoogleSerperRun\\n   - HumanInputRun\\n   - MetaphorSearchResults\\n   - SearxSearchResults\\n   - SearxSearchRun\\n   - WikipediaQueryRun\\n   - WolframAlphaQueryRun\\n   - OpenWeatherMapQueryRun\\n\\n6. Utilities:\\n   - ArxivAPIWrapper\\n   - BingSearchAPIWrapper\\n   - DuckDuckGoSearchAPIWrapper\\n   - GoogleSearchAPIWrapper\\n   - GoogleSerperAPIWrapper\\n   - MetaphorSearchAPIWrapper\\n   - LambdaWrapper\\n   - GraphQLAPIWrapper\\n   - SearxSearchWrapper\\n   - SerpAPIWrapper\\n   - TwilioAPIWrapper\\n   - WikipediaAPIWrapper\\n   - WolframAlphaAPIWrapper\\n   - OpenWeatherMapAPIWrapper\\n\\nPlease note that this list is not exhaustive and only includes the main classes for each category. There might be other classes and subclasses within the LangChain library.\")],\n",
       " 'answer': \"The LangChain class hierarchy consists of various classes and modules, organized mainly into Agents, Chains, LLMs (Language Models), Prompts, Tools, and Utilities. Here's an overview of the main classes in each category:\\n\\n1. Agents:\\n   - MRKLChain\\n   - ReActChain\\n   - SelfAskWithSearchChain\\n\\n2. Chains:\\n   - Base Chains:\\n     - Chain\\n     - APIChain\\n     - LLMChain\\n     - LLMBashChain\\n     - LLMCheckerChain\\n     - LLMMathChain\\n     - PALChain\\n     - QAWithSourcesChain\\n     - SQLDatabaseChain\\n     - VectorDBQA\\n     - VectorDBQAWithSourcesChain\\n   - Conversational Chains:\\n     - ConversationChain\\n     - TaskCreationChain\\n     - TaskPrioritizationChain\\n   - Specialized Chains:\\n     - ConstitutionalChain\\n     - ChatVectorDBChain\\n     - ConversationalRetrievalChain\\n     - RouterChain\\n     - MultiRouteChain\\n     - MultiPromptChain\\n     - MultiRetrievalQAChain\\n     - LLMRouterChain\\n\\n3. LLMs (Language Models):\\n   - AI21\\n   - AlephAlpha\\n   - Anthropic\\n   - Anyscale\\n   - Banana\\n   - Beam\\n   - Bedrock\\n   - CerebriumAI\\n   - Cohere\\n   - CTransformers\\n   - Databricks\\n   - DeepInfra\\n   - FakeListLLM\\n   - ForefrontAI\\n   - GooglePalm\\n   - GooseAI\\n   - GPT4All\\n   - HuggingFaceEndpoint\\n   - HuggingFaceHub\\n   - HuggingFacePipeline\\n   - HuggingFaceTextGenInference\\n   - HumanInputLLM\\n   - LlamaCpp\\n   - Modal\\n   - MosaicML\\n   - NLPCloud\\n   - OpenAI\\n   - OpenAIChat\\n   - OpenLM\\n   - Petals\\n   - PipelineAI\\n   - Replicate\\n   - RWKV\\n   - SagemakerEndpoint\\n   - StochasticAI\\n   - VertexAI\\n   - Writer\\n\\n4. Prompts:\\n   - BasePromptTemplate\\n   - FewShotPromptTemplate\\n   - Prompt\\n   - PromptTemplate\\n\\n5. Tools:\\n   - ArxivQueryRun\\n   - BingSearchRun\\n   - DuckDuckGoSearchRun\\n   - GoogleSearchResults\\n   - GoogleSearchRun\\n   - GoogleSerperResults\\n   - GoogleSerperRun\\n   - HumanInputRun\\n   - MetaphorSearchResults\\n   - SearxSearchResults\\n   - SearxSearchRun\\n   - WikipediaQueryRun\\n   - WolframAlphaQueryRun\\n   - OpenWeatherMapQueryRun\\n\\n6. Utilities:\\n   - ArxivAPIWrapper\\n   - BingSearchAPIWrapper\\n   - DuckDuckGoSearchAPIWrapper\\n   - GoogleSearchAPIWrapper\\n   - GoogleSerperAPIWrapper\\n   - MetaphorSearchAPIWrapper\\n   - LambdaWrapper\\n   - GraphQLAPIWrapper\\n   - SearxSearchWrapper\\n   - SerpAPIWrapper\\n   - TwilioAPIWrapper\\n   - WikipediaAPIWrapper\\n   - WolframAlphaAPIWrapper\\n   - OpenWeatherMapAPIWrapper\\n\\nPlease note that this list is not exhaustive and only includes the main classes for each category. There might be other classes and subclasses within the LangChain library.\",\n",
       " 'source_documents': [Document(page_content='from langchain.agents import MRKLChain, ReActChain, SelfAskWithSearchChain\\nfrom langchain.cache import BaseCache\\nfrom langchain.chains import (\\n    ConversationChain,\\n    LLMBashChain,\\n    LLMChain,\\n    LLMCheckerChain,\\n    LLMMathChain,\\n    PALChain,\\n    QAWithSourcesChain,\\n    SQLDatabaseChain,\\n    VectorDBQA,\\n    VectorDBQAWithSourcesChain,\\n)\\nfrom langchain.docstore import InMemoryDocstore, Wikipedia\\nfrom langchain.llms import (\\n    Anthropic,\\n    Banana,\\n    CerebriumAI,\\n    Cohere,\\n    ForefrontAI,\\n    GooseAI,\\n    HuggingFaceHub,\\n    HuggingFaceTextGenInference,\\n    LlamaCpp,\\n    Modal,\\n    OpenAI,\\n    Petals,\\n    PipelineAI,\\n    SagemakerEndpoint,\\n    StochasticAI,\\n    Writer,\\n)\\nfrom langchain.llms.huggingface_pipeline import HuggingFacePipeline\\nfrom langchain.prompts import (\\n    BasePromptTemplate,\\n    FewShotPromptTemplate,\\n    Prompt,\\n    PromptTemplate,\\n)\\nfrom langchain.sql_database import SQLDatabase\\nfrom langchain.utilities.arxiv import ArxivAPIWrapper\\nfrom langchain.utilities.google_search import GoogleSearchAPIWrapper\\nfrom langchain.utilities.google_serper import GoogleSerperAPIWrapper\\nfrom langchain.utilities.powerbi import PowerBIDataset\\nfrom langchain.utilities.searx_search import SearxSearchWrapper\\nfrom langchain.utilities.serpapi import SerpAPIWrapper\\nfrom langchain.utilities.wikipedia import WikipediaAPIWrapper\\nfrom langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\\nfrom langchain.vectorstores import FAISS, ElasticVectorSearch', metadata={'source': '../data/langchain/langchain/__init__.py'}),\n",
       "  Document(page_content='from langchain.chains.api.base import APIChain\\nfrom langchain.chains.base import Chain\\nfrom langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain\\nfrom langchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain\\nfrom langchain.chains.combine_documents.refine import RefineDocumentsChain\\nfrom langchain.chains.combine_documents.stuff import StuffDocumentsChain\\nfrom langchain.chains.hyde.base import HypotheticalDocumentEmbedder\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.chains.llm_bash.base import LLMBashChain\\nfrom langchain.chains.llm_checker.base import LLMCheckerChain\\nfrom langchain.chains.llm_math.base import LLMMathChain\\nfrom langchain.chains.llm_requests import LLMRequestsChain\\nfrom langchain.chains.pal.base import PALChain\\nfrom langchain.chains.qa_with_sources.base import QAWithSourcesChain\\nfrom langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain\\nfrom langchain.chains.retrieval_qa.base import VectorDBQA\\nfrom langchain.chains.sql_database.base import SQLDatabaseChain\\nfrom langchain.llms.loading import load_llm, load_llm_from_config\\nfrom langchain.prompts.loading import load_prompt, load_prompt_from_config\\nfrom langchain.utilities.loading import try_load_from_hub', metadata={'source': '../data/langchain/langchain/chains/loading.py'}),\n",
       "  Document(page_content='\"\"\"Chains are easily reusable components which can be linked together.\"\"\"\\nfrom langchain.chains.api.base import APIChain\\nfrom langchain.chains.api.openapi.chain import OpenAPIEndpointChain\\nfrom langchain.chains.combine_documents.base import AnalyzeDocumentChain\\nfrom langchain.chains.constitutional_ai.base import ConstitutionalChain\\nfrom langchain.chains.conversation.base import ConversationChain\\nfrom langchain.chains.conversational_retrieval.base import (\\n    ChatVectorDBChain,\\n    ConversationalRetrievalChain,\\n)\\nfrom langchain.chains.flare.base import FlareChain\\nfrom langchain.chains.graph_qa.base import GraphQAChain\\nfrom langchain.chains.graph_qa.cypher import GraphCypherQAChain\\nfrom langchain.chains.hyde.base import HypotheticalDocumentEmbedder\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.chains.llm_bash.base import LLMBashChain\\nfrom langchain.chains.llm_checker.base import LLMCheckerChain\\nfrom langchain.chains.llm_math.base import LLMMathChain\\nfrom langchain.chains.llm_requests import LLMRequestsChain\\nfrom langchain.chains.llm_summarization_checker.base import LLMSummarizationCheckerChain\\nfrom langchain.chains.loading import load_chain\\nfrom langchain.chains.mapreduce import MapReduceChain\\nfrom langchain.chains.moderation import OpenAIModerationChain\\nfrom langchain.chains.pal.base import PALChain\\nfrom langchain.chains.qa_generation.base import QAGenerationChain\\nfrom langchain.chains.qa_with_sources.base import QAWithSourcesChain\\nfrom langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\\nfrom langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain\\nfrom langchain.chains.retrieval_qa.base import RetrievalQA, VectorDBQA\\nfrom langchain.chains.sequential import SequentialChain, SimpleSequentialChain\\nfrom langchain.chains.sql_database.base import (\\n    SQLDatabaseChain,\\n    SQLDatabaseSequentialChain,\\n)\\nfrom langchain.chains.transform import TransformChain', metadata={'source': '../data/langchain/langchain/chains/__init__.py'}),\n",
       "  Document(page_content='import langchain\\nfrom langchain.callbacks.base import (\\n    BaseCallbackHandler,\\n    BaseCallbackManager,\\n    ChainManagerMixin,\\n    LLMManagerMixin,\\n    RunManagerMixin,\\n    ToolManagerMixin,\\n)\\nfrom langchain.callbacks.openai_info import OpenAICallbackHandler\\nfrom langchain.callbacks.stdout import StdOutCallbackHandler\\nfrom langchain.callbacks.tracers.langchain import LangChainTracer\\nfrom langchain.callbacks.tracers.langchain_v1 import LangChainTracerV1, TracerSessionV1\\nfrom langchain.callbacks.tracers.schemas import TracerSession\\nfrom langchain.callbacks.tracers.stdout import ConsoleCallbackHandler\\nfrom langchain.callbacks.tracers.wandb import WandbTracer\\nfrom langchain.schema import (\\n    AgentAction,\\n    AgentFinish,\\n    BaseMessage,\\n    LLMResult,\\n    get_buffer_string,\\n)\\n\\nlogger = logging.getLogger(__name__)\\nCallbacks = Optional[Union[List[BaseCallbackHandler], BaseCallbackManager]]', metadata={'source': '../data/langchain/langchain/callbacks/manager.py'}),\n",
       "  Document(page_content='\"\"\"Base interface that all chains should implement.\"\"\"\\nimport inspect\\nimport json\\nimport warnings\\nfrom abc import ABC, abstractmethod\\nfrom pathlib import Path\\nfrom typing import Any, Dict, List, Optional, Union\\n\\nimport yaml\\nfrom pydantic import BaseModel, Field, root_validator, validator\\n\\nimport langchain\\nfrom langchain.callbacks.base import BaseCallbackManager\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManager,\\n    AsyncCallbackManagerForChainRun,\\n    CallbackManager,\\n    CallbackManagerForChainRun,\\n    Callbacks,\\n)\\nfrom langchain.schema import BaseMemory\\n\\n\\ndef _get_verbosity() -> bool:\\n    return langchain.verbose\\n\\n\\nclass Chain(BaseModel, ABC):\\n    \"\"\"Base interface that all chains should implement.\"\"\"', metadata={'source': '../data/langchain/langchain/chains/base.py'}),\n",
       "  Document(page_content='from langchain import LLMChain, PromptTemplate\\nfrom langchain.base_language import BaseLanguageModel\\n\\n\\nclass TaskPrioritizationChain(LLMChain):\\n    \"\"\"Chain to prioritize tasks.\"\"\"', metadata={'source': '../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_prioritization.py'}),\n",
       "  Document(page_content='from langchain.llms.ai21 import AI21\\nfrom langchain.llms.aleph_alpha import AlephAlpha\\nfrom langchain.llms.anthropic import Anthropic\\nfrom langchain.llms.anyscale import Anyscale\\nfrom langchain.llms.bananadev import Banana\\nfrom langchain.llms.base import BaseLLM\\nfrom langchain.llms.beam import Beam\\nfrom langchain.llms.bedrock import Bedrock\\nfrom langchain.llms.cerebriumai import CerebriumAI\\nfrom langchain.llms.cohere import Cohere\\nfrom langchain.llms.ctransformers import CTransformers\\nfrom langchain.llms.databricks import Databricks\\nfrom langchain.llms.deepinfra import DeepInfra\\nfrom langchain.llms.fake import FakeListLLM\\nfrom langchain.llms.forefrontai import ForefrontAI\\nfrom langchain.llms.google_palm import GooglePalm\\nfrom langchain.llms.gooseai import GooseAI\\nfrom langchain.llms.gpt4all import GPT4All\\nfrom langchain.llms.huggingface_endpoint import HuggingFaceEndpoint\\nfrom langchain.llms.huggingface_hub import HuggingFaceHub\\nfrom langchain.llms.huggingface_pipeline import HuggingFacePipeline\\nfrom langchain.llms.huggingface_text_gen_inference import HuggingFaceTextGenInference\\nfrom langchain.llms.human import HumanInputLLM\\nfrom langchain.llms.llamacpp import LlamaCpp\\nfrom langchain.llms.modal import Modal\\nfrom langchain.llms.mosaicml import MosaicML\\nfrom langchain.llms.nlpcloud import NLPCloud\\nfrom langchain.llms.openai import AzureOpenAI, OpenAI, OpenAIChat\\nfrom langchain.llms.openlm import OpenLM\\nfrom langchain.llms.petals import Petals\\nfrom langchain.llms.pipelineai import PipelineAI\\nfrom langchain.llms.predictionguard import PredictionGuard\\nfrom langchain.llms.promptlayer_openai import PromptLayerOpenAI, PromptLayerOpenAIChat\\nfrom langchain.llms.replicate import Replicate\\nfrom langchain.llms.rwkv import RWKV\\nfrom langchain.llms.sagemaker_endpoint import SagemakerEndpoint\\nfrom langchain.llms.self_hosted import SelfHostedPipeline\\nfrom langchain.llms.self_hosted_hugging_face import SelfHostedHuggingFaceLLM\\nfrom langchain.llms.stochasticai import StochasticAI\\nfrom langchain.llms.vertexai import VertexAI\\nfrom langchain.llms.writer import Writer', metadata={'source': '../data/langchain/langchain/llms/__init__.py'}),\n",
       "  Document(page_content='\"\"\"Tests for correct functioning of chains.\"\"\"', metadata={'source': '../data/langchain/tests/unit_tests/chains/__init__.py'}),\n",
       "  Document(page_content='from langchain.chains.router.base import MultiRouteChain, RouterChain\\nfrom langchain.chains.router.llm_router import LLMRouterChain\\nfrom langchain.chains.router.multi_prompt import MultiPromptChain\\nfrom langchain.chains.router.multi_retrieval_qa import MultiRetrievalQAChain\\n\\n__all__ = [\\n    \"RouterChain\",\\n    \"MultiRouteChain\",\\n    \"MultiPromptChain\",\\n    \"MultiRetrievalQAChain\",\\n    \"LLMRouterChain\",\\n]', metadata={'source': '../data/langchain/langchain/chains/router/__init__.py'}),\n",
       "  Document(page_content='@property\\n    def _chain_type(self) -> str:\\n        return \"llm_bash_chain\"', metadata={'source': '../data/langchain/langchain/chains/llm_bash/base.py'}),\n",
       "  Document(page_content='\"\"\"Chain for applying constitutional principles to the outputs of another chain.\"\"\"\\nfrom typing import Any, Dict, List, Optional\\n\\nfrom langchain.base_language import BaseLanguageModel\\nfrom langchain.callbacks.manager import CallbackManagerForChainRun\\nfrom langchain.chains.base import Chain\\nfrom langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\\nfrom langchain.chains.constitutional_ai.principles import PRINCIPLES\\nfrom langchain.chains.constitutional_ai.prompts import CRITIQUE_PROMPT, REVISION_PROMPT\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.prompts.base import BasePromptTemplate\\n\\n\\nclass ConstitutionalChain(Chain):\\n    \"\"\"Chain for applying constitutional principles.\\n\\n    Example:\\n        .. code-block:: python\\n\\n            from langchain.llms import OpenAI\\n            from langchain.chains import LLMChain, ConstitutionalChain\\n            from langchain.chains.constitutional_ai.models \\\\\\n                import ConstitutionalPrinciple', metadata={'source': '../data/langchain/langchain/chains/constitutional_ai/base.py'}),\n",
       "  Document(page_content='\"\"\"LangChain+ Client.\"\"\"\\n\\n\\nfrom langchain.client.langchain import LangChainPlusClient\\n\\n__all__ = [\"LangChainPlusClient\"]', metadata={'source': '../data/langchain/langchain/client/__init__.py'}),\n",
       "  Document(page_content='@property\\n    def _chain_type(self) -> str:\\n        return \"llm_bash_chain\"\\n\\n    @classmethod\\n    def from_llm(\\n        cls,\\n        llm: BaseLanguageModel,\\n        prompt: BasePromptTemplate = PROMPT,\\n        **kwargs: Any,\\n    ) -> LLMBashChain:\\n        llm_chain = LLMChain(llm=llm, prompt=prompt)\\n        return cls(llm_chain=llm_chain, **kwargs)', metadata={'source': '../data/langchain/langchain/chains/llm_bash/base.py'}),\n",
       "  Document(page_content='@property\\n    def _chain_type(self) -> str:\\n        return \"llm_chain\"\\n\\n    @classmethod\\n    def from_string(cls, llm: BaseLanguageModel, template: str) -> Chain:\\n        \"\"\"Create LLMChain from LLM and template.\"\"\"\\n        prompt_template = PromptTemplate.from_template(template)\\n        return cls(llm=llm, prompt=prompt_template)', metadata={'source': '../data/langchain/langchain/chains/llm.py'}),\n",
       "  Document(page_content='\"\"\"Callback handlers that allow listening to events in LangChain.\"\"\"\\n\\nfrom langchain.callbacks.aim_callback import AimCallbackHandler\\nfrom langchain.callbacks.clearml_callback import ClearMLCallbackHandler\\nfrom langchain.callbacks.comet_ml_callback import CometCallbackHandler\\nfrom langchain.callbacks.manager import (\\n    get_openai_callback,\\n    tracing_enabled,\\n    wandb_tracing_enabled,\\n)\\nfrom langchain.callbacks.mlflow_callback import MlflowCallbackHandler\\nfrom langchain.callbacks.openai_info import OpenAICallbackHandler\\nfrom langchain.callbacks.stdout import StdOutCallbackHandler\\nfrom langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler\\nfrom langchain.callbacks.wandb_callback import WandbCallbackHandler\\nfrom langchain.callbacks.whylabs_callback import WhyLabsCallbackHandler', metadata={'source': '../data/langchain/langchain/callbacks/__init__.py'}),\n",
       "  Document(page_content='from langchain.agents.tools import Tool\\nfrom langchain.base_language import BaseLanguageModel\\nfrom langchain.callbacks.base import BaseCallbackManager\\nfrom langchain.callbacks.manager import Callbacks\\nfrom langchain.chains.api import news_docs, open_meteo_docs, podcast_docs, tmdb_docs\\nfrom langchain.chains.api.base import APIChain\\nfrom langchain.chains.llm_math.base import LLMMathChain\\nfrom langchain.chains.pal.base import PALChain\\nfrom langchain.requests import TextRequestsWrapper\\nfrom langchain.tools.arxiv.tool import ArxivQueryRun\\nfrom langchain.tools.base import BaseTool\\nfrom langchain.tools.bing_search.tool import BingSearchRun\\nfrom langchain.tools.ddg_search.tool import DuckDuckGoSearchRun\\nfrom langchain.tools.google_search.tool import GoogleSearchResults, GoogleSearchRun\\nfrom langchain.tools.metaphor_search.tool import MetaphorSearchResults\\nfrom langchain.tools.google_serper.tool import GoogleSerperResults, GoogleSerperRun\\nfrom langchain.tools.graphql.tool import BaseGraphQLTool\\nfrom langchain.tools.human.tool import HumanInputRun\\nfrom langchain.tools.python.tool import PythonREPLTool\\nfrom langchain.tools.requests.tool import (\\n    RequestsDeleteTool,\\n    RequestsGetTool,\\n    RequestsPatchTool,\\n    RequestsPostTool,\\n    RequestsPutTool,\\n)\\nfrom langchain.tools.scenexplain.tool import SceneXplainTool\\nfrom langchain.tools.searx_search.tool import SearxSearchResults, SearxSearchRun\\nfrom langchain.tools.shell.tool import ShellTool\\nfrom langchain.tools.wikipedia.tool import WikipediaQueryRun\\nfrom langchain.tools.wolfram_alpha.tool import WolframAlphaQueryRun\\nfrom langchain.tools.openweathermap.tool import OpenWeatherMapQueryRun\\nfrom langchain.utilities import ArxivAPIWrapper\\nfrom langchain.utilities.bing_search import BingSearchAPIWrapper\\nfrom langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\\nfrom langchain.utilities.google_search import GoogleSearchAPIWrapper\\nfrom langchain.utilities.google_serper import GoogleSerperAPIWrapper\\nfrom langchain.utilities.metaphor_search import MetaphorSearchAPIWrapper\\nfrom langchain.utilities.awslambda import LambdaWrapper\\nfrom langchain.utilities.graphql import GraphQLAPIWrapper\\nfrom langchain.utilities.searx_search import SearxSearchWrapper\\nfrom langchain.utilities.serpapi import SerpAPIWrapper\\nfrom langchain.utilities.twilio import TwilioAPIWrapper\\nfrom langchain.utilities.wikipedia import WikipediaAPIWrapper\\nfrom langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\\nfrom langchain.utilities.openweathermap import OpenWeatherMapAPIWrapper', metadata={'source': '../data/langchain/langchain/agents/load_tools.py'}),\n",
       "  Document(page_content='@property\\n    def _chain_type(self) -> str:\\n        return \"llm_checker_chain\"\\n\\n    @classmethod\\n    def from_llm(\\n        cls,\\n        llm: BaseLanguageModel,\\n        create_draft_answer_prompt: PromptTemplate = CREATE_DRAFT_ANSWER_PROMPT,\\n        list_assertions_prompt: PromptTemplate = LIST_ASSERTIONS_PROMPT,\\n        check_assertions_prompt: PromptTemplate = CHECK_ASSERTIONS_PROMPT,\\n        revised_answer_prompt: PromptTemplate = REVISED_ANSWER_PROMPT,\\n        **kwargs: Any,\\n    ) -> LLMCheckerChain:\\n        question_to_checked_assertions_chain = (\\n            _load_question_to_checked_assertions_chain(\\n                llm,\\n                create_draft_answer_prompt,\\n                list_assertions_prompt,\\n                check_assertions_prompt,\\n                revised_answer_prompt,\\n            )\\n        )\\n        return cls(\\n            question_to_checked_assertions_chain=question_to_checked_assertions_chain,\\n            **kwargs,\\n        )', metadata={'source': '../data/langchain/langchain/chains/llm_checker/base.py'}),\n",
       "  Document(page_content='\"\"\"Chain for chatting with a vector database.\"\"\"\\nfrom __future__ import annotations\\n\\nimport warnings\\nfrom abc import abstractmethod\\nfrom pathlib import Path\\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Union\\n\\nfrom pydantic import Extra, Field, root_validator\\n\\nfrom langchain.base_language import BaseLanguageModel\\nfrom langchain.callbacks.manager import (\\n    AsyncCallbackManagerForChainRun,\\n    CallbackManagerForChainRun,\\n)\\nfrom langchain.chains.base import Chain\\nfrom langchain.chains.combine_documents.base import BaseCombineDocumentsChain\\nfrom langchain.chains.combine_documents.stuff import StuffDocumentsChain\\nfrom langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\\nfrom langchain.chains.llm import LLMChain\\nfrom langchain.chains.question_answering import load_qa_chain\\nfrom langchain.prompts.base import BasePromptTemplate\\nfrom langchain.schema import BaseMessage, BaseRetriever, Document\\nfrom langchain.vectorstores.base import VectorStore', metadata={'source': '../data/langchain/langchain/chains/conversational_retrieval/base.py'}),\n",
       "  Document(page_content='from langchain import LLMChain, PromptTemplate\\nfrom langchain.base_language import BaseLanguageModel\\n\\n\\nclass TaskCreationChain(LLMChain):\\n    \"\"\"Chain to generates tasks.\"\"\"', metadata={'source': '../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_creation.py'}),\n",
       "  Document(page_content='class TaskPrioritizationChain(LLMChain):\\n    \"\"\"Chain to prioritize tasks.\"\"\"\\n\\n    @classmethod\\n    def from_llm(cls, llm: BaseLanguageModel, verbose: bool = True) -> LLMChain:\\n        \"\"\"Get the response parser.\"\"\"\\n        task_prioritization_template = (\\n            \"You are a task prioritization AI tasked with cleaning the formatting of \"\\n            \"and reprioritizing the following tasks: {task_names}.\"\\n            \" Consider the ultimate objective of your team: {objective}.\"\\n            \" Do not remove any tasks. Return the result as a numbered list, like:\"\\n            \" #. First task\"\\n            \" #. Second task\"\\n            \" Start the task list with number {next_task_id}.\"\\n        )\\n        prompt = PromptTemplate(\\n            template=task_prioritization_template,\\n            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\\n        )\\n        return cls(prompt=prompt, llm=llm, verbose=verbose)', metadata={'source': '../data/langchain/langchain/experimental/autonomous_agents/baby_agi/task_prioritization.py'})]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "-> **Question**: What is the class hierarchy? \n",
    "\n",
    "**Answer**: There are several class hierarchies in the provided code, so I'll list a few:\n",
    "\n",
    "1. `BaseModel` -> `ConstitutionalPrinciple`: `ConstitutionalPrinciple` is a subclass of `BaseModel`.\n",
    "2. `BasePromptTemplate` -> `StringPromptTemplate`, `AIMessagePromptTemplate`, `BaseChatPromptTemplate`, `ChatMessagePromptTemplate`, `ChatPromptTemplate`, `HumanMessagePromptTemplate`, `MessagesPlaceholder`, `SystemMessagePromptTemplate`, `FewShotPromptTemplate`, `FewShotPromptWithTemplates`, `Prompt`, `PromptTemplate`: All of these classes are subclasses of `BasePromptTemplate`.\n",
    "3. `APIChain`, `Chain`, `MapReduceDocumentsChain`, `MapRerankDocumentsChain`, `RefineDocumentsChain`, `StuffDocumentsChain`, `HypotheticalDocumentEmbedder`, `LLMChain`, `LLMBashChain`, `LLMCheckerChain`, `LLMMathChain`, `LLMRequestsChain`, `PALChain`, `QAWithSourcesChain`, `VectorDBQAWithSourcesChain`, `VectorDBQA`, `SQLDatabaseChain`: All of these classes are subclasses of `Chain`.\n",
    "4. `BaseLoader`: `BaseLoader` is a subclass of `ABC`.\n",
    "5. `BaseTracer` -> `ChainRun`, `LLMRun`, `SharedTracer`, `ToolRun`, `Tracer`, `TracerException`, `TracerSession`: All of these classes are subclasses of `BaseTracer`.\n",
    "6. `OpenAIEmbeddings`, `HuggingFaceEmbeddings`, `CohereEmbeddings`, `JinaEmbeddings`, `LlamaCppEmbeddings`, `HuggingFaceHubEmbeddings`, `TensorflowHubEmbeddings`, `SagemakerEndpointEmbeddings`, `HuggingFaceInstructEmbeddings`, `SelfHostedEmbeddings`, `SelfHostedHuggingFaceEmbeddings`, `SelfHostedHuggingFaceInstructEmbeddings`, `FakeEmbeddings`, `AlephAlphaAsymmetricSemanticEmbedding`, `AlephAlphaSymmetricSemanticEmbedding`: All of these classes are subclasses of `BaseLLM`. \n",
    "\n",
    "\n",
    "-> **Question**: What classes are derived from the Chain class? \n",
    "\n",
    "**Answer**: There are multiple classes that are derived from the Chain class. Some of them are:\n",
    "- APIChain\n",
    "- AnalyzeDocumentChain\n",
    "- ChatVectorDBChain\n",
    "- CombineDocumentsChain\n",
    "- ConstitutionalChain\n",
    "- ConversationChain\n",
    "- GraphQAChain\n",
    "- HypotheticalDocumentEmbedder\n",
    "- LLMChain\n",
    "- LLMCheckerChain\n",
    "- LLMRequestsChain\n",
    "- LLMSummarizationCheckerChain\n",
    "- MapReduceChain\n",
    "- OpenAPIEndpointChain\n",
    "- PALChain\n",
    "- QAWithSourcesChain\n",
    "- RetrievalQA\n",
    "- RetrievalQAWithSourcesChain\n",
    "- SequentialChain\n",
    "- SQLDatabaseChain\n",
    "- TransformChain\n",
    "- VectorDBQA\n",
    "- VectorDBQAWithSourcesChain\n",
    "\n",
    "There might be more classes that are derived from the Chain class as it is possible to create custom classes that extend the Chain class.\n",
    "\n",
    "\n",
    "-> **Question**: What classes and functions in the ./langchain/utilities/ forlder are not covered by unit tests? \n",
    "\n",
    "**Answer**: All classes and functions in the `./langchain/utilities/` folder seem to have unit tests written for them. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
